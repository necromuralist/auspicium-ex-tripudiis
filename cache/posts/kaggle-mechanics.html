<div id="outline-container-orgce3f9e2" class="outline-2">
<h2 id="orgce3f9e2">The Basics</h2>
<div class="outline-text-2" id="text-orgce3f9e2">
</div>
<div id="outline-container-org7f26de2" class="outline-3">
<h3 id="org7f26de2">Data</h3>
<div class="outline-text-3" id="text-org7f26de2">
<p>
Every competition provides data so you can create a model, but there isn't a standardized format. Sometimes it will be CSVz, sometimes excel spreadsheets, sometimes image files, the sources can vary so you should read the data descriptions and adapt what you do to the competition. You aren't always limited to the data that is provided. If you were creating an image recognition model, for instance, it might be okay to include outside images or pre-trained models, it depends on the particulars of the competition.
</p>
</div>
</div>
<div id="outline-container-orgbecc6e6" class="outline-3">
<h3 id="orgbecc6e6">Models</h3>
<div class="outline-text-3" id="text-orgbecc6e6">
<p>
This is what you are trying to create - a representation of the population based on the data you are given that will allow you to predict outcomes based on inputs not given in the data. The model needs two main features:
</p>
<ul class="org-ul">
<li>accuracy</li>
<li>reproducibility</li>
</ul>

<p>
Note that a model is not the same as an algorithm. You might have to combine multiple algorithms in order to build your model. The key to a model is that it maps inputs to outputs.
</p>
</div>
</div>
<div id="outline-container-orgcb52dec" class="outline-3">
<h3 id="orgcb52dec">Submission</h3>
<div class="outline-text-3" id="text-orgcb52dec">
<p>
Your submission is typically your predictions on a test set. This isn't always the case but it is the most common way that the competitions are run.
</p>
</div>
</div>
<div id="outline-container-orgfcbfdce" class="outline-3">
<h3 id="orgfcbfdce">Evaluation</h3>
<div class="outline-text-3" id="text-orgfcbfdce">
<p>
How can you tell how well your model does? You need a function that maps your model and a data set to a score that evaluates how well the model does. There are many different metrics to use (accuracy, precision, recall, etc.) but the competition will choose one and tell you what it is in the description so make sure you read the description to get it.
</p>
</div>
</div>
<div id="outline-container-org813331e" class="outline-3">
<h3 id="org813331e">Leaderboard</h3>
<div class="outline-text-3" id="text-org813331e">
<p>
This is the relative ranking of the participants in the competition. This is what makes it a competition. Even if your metric tells you your model is doing well, if you are ranked at the bottom, you still won't win. There are actually two leaderboards - public and private. The evaluation dataset is split by kaggle into two sets, public and private, and during the competition the results of testing on the public data are shown on the leaderborad. Once the competition is over the leaderboard is displayed using the evaluations using the private data.
</p>
</div>
</div>
</div>
<div id="outline-container-org4a5b81d" class="outline-2">
<h2 id="org4a5b81d">Other Competitions</h2>
<div class="outline-text-2" id="text-org4a5b81d">
<p>
<a href="https://www.kaggle.com/">Kaggle</a> isn't the only one running data-science competititons. Here are some others.
</p>

<ul class="org-ul">
<li><a href="https://www.drivendata.org/">Driven Data</a>: Data Science competititons aimed at social problems</li>
<li><a href="http://codalab.org/">Coda Lab</a>: Competitions using research datasets</li>
<li><a href="https://www.datasciencechallenge.org/">Data Science Challenge</a>: Using data-science to solve government-scale problems.</li>
<li><a href="https://www.datascience.net/fr/challenge#">Data Science dot net</a>: A european data-science competition site.</li>
</ul>
</div>
</div>
