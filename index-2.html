<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Notes on studying kaggle.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Notes on Kaggle (old posts, page 2) | Notes on Kaggle</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="https://necromuralist.github.io/Kaggle-Competitions/index-2.html">
<link rel="prev" href="." type="text/html">
<link rel="next" href="index-1.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-default navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://necromuralist.github.io/Kaggle-Competitions/">

                <span id="blog-title">Notes on Kaggle</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="https://necromuralist.github.io/">The Cloistered Monkey</a>
                </li>
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>
                </li>
<li>
<a href="rss.xml">RSS feed</a>

                
            </li>
</ul>
<!-- Google custom search --><form method="get" action="https://www.google.com/search" class="navbar-form navbar-right" role="search">
<div class="form-group">
<input type="text" name="q" class="form-control" placeholder="Search">
</div>
<button type="submit" class="btn btn-primary">
	<span class="glyphicon glyphicon-search"></span>
</button>
<input type="hidden" name="sitesearch" value="https://necromuralist.github.io/Kaggle-Competitions/">
</form>
<!-- End of custom search -->


            <ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/feature-extraction-from-text-and-images/" class="u-url">Feature Extraction From Text and Images</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/feature-extraction-from-text-and-images/" rel="bookmark"><time class="published dt-published" datetime="2018-08-13T07:17:52-07:00" title="2018-08-13 07:17">2018-08-13 07:17</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/feature-extraction-from-text-and-images/#orgfeb2b30">How do you convert text to data?</a></li>
<li><a href="posts/feature-extraction-from-text-and-images/#orgd0d2c46">Practice Quiz</a></li>
<li><a href="posts/feature-extraction-from-text-and-images/#orga47dfcb">Quiz</a></li>
<li><a href="posts/feature-extraction-from-text-and-images/#orgeb9a2d8">Links</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgfeb2b30" class="outline-2">
<h2 id="orgfeb2b30">How do you convert text to data?</h2>
<div class="outline-text-2" id="text-orgfeb2b30">
</div>
<div id="outline-container-org2bfe738" class="outline-3">
<h3 id="org2bfe738">Two Main Methods</h3>
<div class="outline-text-3" id="text-org2bfe738">
</div>
<div id="outline-container-orga60dac5" class="outline-4">
<h4 id="orga60dac5">Bag Of Words</h4>
<div class="outline-text-4" id="text-orga60dac5">
</div>
<ul class="org-ul">
<li>
<a id="org9bb0d0f"></a>Vectorization<br><div class="outline-text-5" id="text-org9bb0d0f">
<p>
This method counts the number of occurrences of each word in the source. For each word it creates a column and then in the row puts the counts for that instance of data.
</p>
<ul class="org-ul">
<li>Sklearn implements this with <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">CountVectorizer</a>
</li>
</ul>
</div>
</li>
<li>
<a id="orgb771ad6"></a>Term Frequency/Inverse Document Frequency (TF/IDF)<br><div class="outline-text-5" id="text-orgb771ad6">
<p>
This method tries to make word counts comparable even if the texts are of different sizes and also to emphasize more important words.
</p>
<ul class="org-ul">
<li>Term Frequency: Normalize rows so all values are from 0 to 1 to make texts of different sizes comparable</li>
<li>Inverse Document Frequency: Normalize columns to make emphasize more important features</li>
<li>Sklearn implements this with <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">TfidVectorizer</a>
</li>
</ul>
</div>
</li>
<li>
<a id="orgb6ea07f"></a>N-Grams<br><div class="outline-text-5" id="text-orgb6ea07f">
<p>
This method that creates a bag of words by grouping them into sub-sequences of words. A 3-gram, for instance, sweeps the text to create sequences of words made up of 3 adjacent words.
</p>
<ul class="org-ul">
<li>
<a href="http://sklearn.feature_extraction.text.countvectorizer">Count Vectorizer</a> is sklearn's implementation</li>
</ul>
</div>
</li>
<li>
<a id="org0e2c3f7"></a>Text Preprocessing<br><div class="outline-text-5" id="text-org0e2c3f7">
<ul class="org-ul">
<li>lowercase:
Change all the words to lower-case</li>
<li>lemmatization:
Try to reduce word to a common case (e.g. democratization, democracy, democratic all become democracy)</li>
<li>stemming:
Try to reduce word to a root (e.g. democratization, democracy, democratic all become democ)</li>
<li>stopwords:
Remove common words (e.g. a, and, or, etc.)</li>
</ul>
</div>
</li>
<li>
<a id="org94da243"></a>The Bag Of Words Pipeline<br><div class="outline-text-5" id="text-org94da243">
<ol class="org-ol">
<li>Preprocessing (lowercase, lemmatization, stemming, stopwords)</li>
<li>Create n-grams</li>
<li>Postprocessing: TF/IDF</li>
</ol>
</div>
</li>
</ul>
</div>
<div id="outline-container-org5dfff27" class="outline-4">
<h4 id="org5dfff27">Embeddings (e.g. Word2Vec)</h4>
<div class="outline-text-4" id="text-org5dfff27">
<ul class="org-ul">
<li>Uses neural-nets</li>
<li>much smaller vectors than bag of words</li>
<li>But each word gets a vector so many more vectors</li>
<li>similar words have similar word-vectors</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd0d2c46" class="outline-2">
<h2 id="orgd0d2c46">Practice Quiz</h2>
<div class="outline-text-2" id="text-orgd0d2c46">
</div>
<div id="outline-container-org46a9334" class="outline-3">
<h3 id="org46a9334">One</h3>
<div class="outline-text-3" id="text-org46a9334">
<p>
TF-IDF is applied to a matrix where each column represents a word, each row represents a document, and each value shows the number of times a particular word occurred in a particular document. Choose the correct statements.
</p>
<ul class="org-ul">
<li class="on">
<code>[X]</code> IDF scales features inversely proprotionally to a number of word occurrences over documents</li>
<li class="off">
<code>[ ]</code> IDF scales features proportionally to the frequency of the a word's occurrences</li>
<li class="on">
<code>[X]</code> TF normalizes sums of the row values to 1</li>
<li class="off">
<code>[ ]</code> TF normalizes sums of the column values to 1</li>
</ul>
</div>
</div>
<div id="outline-container-org5c96619" class="outline-3">
<h3 id="org5c96619">Two</h3>
<div class="outline-text-3" id="text-org5c96619">
<p>
Which of these methods can be used to preprocess text?
</p>
<ul class="org-ul">
<li class="on">
<code>[X]</code> stemming</li>
<li class="on">
<code>[X]</code> Lower-case transformation</li>
<li class="on">
<code>[X]</code> Lemmatization</li>
<li class="on">
<code>[X]</code> Stopword removal</li>
<li class="off">
<code>[ ]</code> Levenshteining</li>
<li class="off">
<code>[ ]</code> plumping</li>
<li class="off">
<code>[ ]</code> plumbing</li>
</ul>
</div>
</div>
<div id="outline-container-orgb29fbea" class="outline-3">
<h3 id="orgb29fbea">Three</h3>
<div class="outline-text-3" id="text-orgb29fbea">
<p>
What is the main purpose of lemmatization and stemming?
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> to remove words which are not useful</li>
<li class="on">
<code>[X]</code> to remove inflectional forms and sometimes derivationally related forms of a word to a common base form</li>
<li class="off">
<code>[ ]</code> To reduce the significance of common words</li>
<li class="off">
<code>[ ]</code> to induce common word amplification standards to the most useful for machine learning algorithms form</li>
</ul>
</div>
</div>
<div id="outline-container-org6e9e549" class="outline-3">
<h3 id="org6e9e549">Four</h3>
<div class="outline-text-3" id="text-org6e9e549">
<p>
To learn Word2Vec embeddings we need:
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> GloVe embeddings</li>
<li class="off">
<code>[ ]</code> Labels for the documents in the corpora</li>
<li class="on">
<code>[X]</code> Labels for each word in the documents in the corpora</li>
<li class="on">
<code>[X]</code> Text corpora</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga47dfcb" class="outline-2">
<h2 id="orga47dfcb">Quiz</h2>
<div class="outline-text-2" id="text-orga47dfcb">
</div>
<div id="outline-container-org9f4bf4d" class="outline-3">
<h3 id="org9f4bf4d">One</h3>
<div class="outline-text-3" id="text-org9f4bf4d">
<p>
Select true statements about n-grams.
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> Levenshteining should always be applied before computing n-grams (there is no such thing as Levenshteining)</li>
<li class="off">
<code>[ ]</code> n-grams always help increase significance of important words (n-grams are about counts, not importance)</li>
<li class="on">
<code>[X]</code> n-grams features are typically sparse (n-grams count occurrences of words and not every word will be found in every document)</li>
<li class="on">
<code>[X]</code> n-grams can help utilize local context around each word (n-grams encode sequences of words)</li>
</ul>
</div>
</div>
<div id="outline-container-org121bb24" class="outline-3">
<h3 id="org121bb24">Two</h3>
<div class="outline-text-3" id="text-org121bb24">
<p>
Select the true statements.
</p>
<ul class="org-ul">
<li class="on">
<code>[X]</code> Bag of words usually produces longer vectors than Word2Vec (The number of features with BOW is equal to the number of unique words, Word2Vec limit is set beforehand)</li>
<li class="on">
<code>[X]</code> Semantically similar words usually have similar word2vec embeddings</li>
<li class="off">
<code>[ ]</code> You do not need bag of words features in a competition if you have word2vec features (both approaches are useful and can work together)
<ul class="org-ul">
<li class="off">
<code>[ ]</code> The meaning of each value in the Bag of Words matrix is unknown (The meaning of each value is how many times it occurred)</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org87d4ddc" class="outline-3">
<h3 id="org87d4ddc">Three</h3>
<div class="outline-text-3" id="text-org87d4ddc">
<p>
Suppose in a new competition we are given a dataset of 2D medical images. We want to extract image descriptors from a hidden layer of a neural network pretrained on the ImageNet dataset. We will then use extracted descriptors to train a simple logistic regression model to classify images from our dataset.
</p>

<p>
We are considering using two networks: ResNet-50 with an ImageNet accuracy of X and VGG-16 with an ImageNet accuracy of Y (X &lt; Y). Select the true statements.
</p>

<ul class="org-ul">
<li class="off">
<code>[ ]</code> With one pretrained CNN model you can get only one vector of descriptors for an image</li>
<li class="off">
<code>[ ]</code> Descriptors from ResNet 50 will always be better than the ones from VG-16 in our pipeline</li>
<li class="on">
<code>[X]</code> It is not clear what descriptors are better on our dataset. We should evaluate both.
<ul class="org-ul">
<li class="off">
<code>[ ]</code> Descriptors from ResNet-50 and VGG-16 are always very similar in cosine distance</li>
<li class="off">
<code>[ ]</code> For any image, descriptors from the last hidden layer of ResNet-50 are the same as the descriptors from the last hidden layer of VGG-16</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org95d17e0" class="outline-3">
<h3 id="org95d17e0">Four</h3>
<div class="outline-text-3" id="text-org95d17e0">
<p>
Data augmentation can be used at (1) train time and (2) test time
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> True, False</li>
<li class="off">
<code>[ ]</code> False, True</li>
<li class="on">
<code>[X]</code> True, True</li>
<li class="off">
<code>[ ]</code> False, False</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgeb9a2d8" class="outline-2">
<h2 id="orgeb9a2d8">Links</h2>
<div class="outline-text-2" id="text-orgeb9a2d8">
</div>
<div id="outline-container-org9cb224d" class="outline-3">
<h3 id="org9cb224d">Text</h3>
<div class="outline-text-3" id="text-org9cb224d">
</div>
<div id="outline-container-org2c40d49" class="outline-4">
<h4 id="org2c40d49">Bag Of Words</h4>
<div class="outline-text-4" id="text-org2c40d49">
<ul class="org-ul">
<li><a href="http://scikit-learn.org/stable/modules/feature_extraction.html">SKlearn on feature extraction</a></li>
<li>
<a href="https://andhint.github.io/machine-learning/nlp/Feature-Extraction-From-Text/">blog post</a> on extracting features from text</li>
</ul>
</div>
</div>
<div id="outline-container-orgf58e6c4" class="outline-4">
<h4 id="orgf58e6c4">Word2Vec</h4>
<div class="outline-text-4" id="text-orgf58e6c4">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/tutorials/representation/word2vec">TensorFlow tutorial</a></li>
<li>
<a href="https://rare-technologies.com/word2vec-tutorial/">Blog post tutorial</a> by the author of gensim</li>
<li><a href="https://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/">Text Classification post</a></li>
<li><a href="https://taylorwhitten.github.io/blog/word2vec">Another introduction</a></li>
</ul>
</div>
</div>
<div id="outline-container-orge34e04c" class="outline-4">
<h4 id="orge34e04c">Natural Language Processing with Python</h4>
<div class="outline-text-4" id="text-orge34e04c">
<ul class="org-ul">
<li><a href="http://www.nltk.org/">nltk</a></li>
<li><a href="https://textblob.readthedocs.io/en/dev/">TextBlob</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgfae8717" class="outline-3">
<h3 id="orgfae8717">Images</h3>
<div class="outline-text-3" id="text-orgfae8717">
</div>
<div id="outline-container-org1a02b96" class="outline-4">
<h4 id="org1a02b96">Pre-trained Models</h4>
<div class="outline-text-4" id="text-org1a02b96">
<ul class="org-ul">
<li><a href="https://keras.io/applications/">Keras</a></li>
<li><a href="https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network_p11">How To use a pre-trained model</a></li>
</ul>
</div>
</div>
<div id="outline-container-orga780bd9" class="outline-4">
<h4 id="orga780bd9">Fine-Tuning</h4>
<div class="outline-text-4" id="text-orga780bd9">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/hub/tutorials/image_retraining">Re-train a tensorflow image classifier</a></li>
<li><a href="https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html">Fine-tuning deep learning models in keras</a></li>
</ul>
</div>
</div>
</div>
</div>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="." rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2018         <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a><br>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
