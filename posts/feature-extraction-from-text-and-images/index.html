<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Getting features from text and image data.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Feature Extraction From Text and Images | Notes on Kaggle</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://necromuralist.github.io/Kaggle-Competitions/posts/feature-extraction-from-text-and-images/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script><meta name="author" content="Cloistered Monkey">
<link rel="prev" href="../first-naive-try/" title="First Naive Try" type="text/html">
<link rel="next" href="../building-the-training-set/" title="Building The Training Set" type="text/html">
<meta property="og:site_name" content="Notes on Kaggle">
<meta property="og:title" content="Feature Extraction From Text and Images">
<meta property="og:url" content="https://necromuralist.github.io/Kaggle-Competitions/posts/feature-extraction-from-text-and-images/">
<meta property="og:description" content="Getting features from text and image data.">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2018-08-13T07:17:52-07:00">
<meta property="article:tag" content="featureextraction text images notes">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-default navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://necromuralist.github.io/Kaggle-Competitions/">

                <span id="blog-title">Notes on Kaggle</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="https://necromuralist.github.io/">The Cloistered Monkey</a>
                </li>
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>
                </li>
<li>
<a href="../../rss.xml">RSS feed</a>

                
            </li>
</ul>
<!-- Google custom search --><form method="get" action="https://www.google.com/search" class="navbar-form navbar-right" role="search">
<div class="form-group">
<input type="text" name="q" class="form-control" placeholder="Search">
</div>
<button type="submit" class="btn btn-primary">
	<span class="glyphicon glyphicon-search"></span>
</button>
<input type="hidden" name="sitesearch" value="https://necromuralist.github.io/Kaggle-Competitions/">
</form>
<!-- End of custom search -->


            <ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.org" id="sourcelink">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Feature Extraction From Text and Images</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2018-08-13T07:17:52-07:00" itemprop="datePublished" title="2018-08-13 07:17">2018-08-13 07:17</time></a></p>
            
        <p class="sourceline"><a href="index.org" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org8cb0aa1">How do you convert text to data?</a></li>
<li><a href="#org34c0118">Practice Quiz</a></li>
<li><a href="#org0e0c001">Quiz</a></li>
<li><a href="#orgce3e50a">Links</a></li>
</ul>
</div>
</div>

<div id="outline-container-org8cb0aa1" class="outline-2">
<h2 id="org8cb0aa1">How do you convert text to data?</h2>
<div class="outline-text-2" id="text-org8cb0aa1">
</div>
<div id="outline-container-org93086c0" class="outline-3">
<h3 id="org93086c0">Two Main Methods</h3>
<div class="outline-text-3" id="text-org93086c0">
</div>
<div id="outline-container-orgcc4b03a" class="outline-4">
<h4 id="orgcc4b03a">Bag Of Words</h4>
<div class="outline-text-4" id="text-orgcc4b03a">
</div>
<ul class="org-ul">
<li>
<a id="org6981de9"></a>Vectorization<br><div class="outline-text-5" id="text-org6981de9">
<p>
This method counts the number of occurrences of each word in the source. For each word it creates a column and then in the row puts the counts for that instance of data.
</p>
<ul class="org-ul">
<li>Sklearn implements this with <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">CountVectorizer</a>
</li>
</ul>
</div>
</li>
<li>
<a id="orgb35f8ca"></a>Term Frequency/Inverse Document Frequency (TF/IDF)<br><div class="outline-text-5" id="text-orgb35f8ca">
<p>
This method tries to make word counts comparable even if the texts are of different sizes and also to emphasize more important words.
</p>
<ul class="org-ul">
<li>Term Frequency: Normalize rows so all values are from 0 to 1 to make texts of different sizes comparable</li>
<li>Inverse Document Frequency: Normalize columns to make emphasize more important features</li>
<li>Sklearn implements this with <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">TfidVectorizer</a>
</li>
</ul>
</div>
</li>
<li>
<a id="org1287ef3"></a>N-Grams<br><div class="outline-text-5" id="text-org1287ef3">
<p>
This method that creates a bag of words by grouping them into sub-sequences of words. A 3-gram, for instance, sweeps the text to create sequences of words made up of 3 adjacent words.
</p>
<ul class="org-ul">
<li>
<a href="http://sklearn.feature_extraction.text.countvectorizer">Count Vectorizer</a> is sklearn's implementation</li>
</ul>
</div>
</li>
<li>
<a id="org2a20580"></a>Text Preprocessing<br><div class="outline-text-5" id="text-org2a20580">
<ul class="org-ul">
<li>lowercase:
Change all the words to lower-case</li>
<li>lemmatization:
Try to reduce word to a common case (e.g. democratization, democracy, democratic all become democracy)</li>
<li>stemming:
Try to reduce word to a root (e.g. democratization, democracy, democratic all become democ)</li>
<li>stopwords:
Remove common words (e.g. a, and, or, etc.)</li>
</ul>
</div>
</li>
<li>
<a id="org70714c9"></a>The Bag Of Words Pipeline<br><div class="outline-text-5" id="text-org70714c9">
<ol class="org-ol">
<li>Preprocessing (lowercase, lemmatization, stemming, stopwords)</li>
<li>Create n-grams</li>
<li>Postprocessing: TF/IDF</li>
</ol>
</div>
</li>
</ul>
</div>
<div id="outline-container-orgab7c48e" class="outline-4">
<h4 id="orgab7c48e">Embeddings (e.g. Word2Vec)</h4>
<div class="outline-text-4" id="text-orgab7c48e">
<ul class="org-ul">
<li>Uses neural-nets</li>
<li>much smaller vectors than bag of words</li>
<li>But each word gets a vector so many more vectors</li>
<li>similar words have similar word-vectors</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org34c0118" class="outline-2">
<h2 id="org34c0118">Practice Quiz</h2>
<div class="outline-text-2" id="text-org34c0118">
</div>
<div id="outline-container-org813029b" class="outline-3">
<h3 id="org813029b">One</h3>
<div class="outline-text-3" id="text-org813029b">
<p>
TF-IDF is applied to a matrix where each column represents a word, each row represents a document, and each value shows the number of times a particular word occurred in a particular document. Choose the correct statements.
</p>
<ul class="org-ul">
<li class="on">
<code>[X]</code> IDF scales features inversely proprotionally to a number of word occurrences over documents</li>
<li class="off">
<code>[ ]</code> IDF scales features proportionally to the frequency of the a word's occurrences</li>
<li class="on">
<code>[X]</code> TF normalizes sums of the row values to 1</li>
<li class="off">
<code>[ ]</code> TF normalizes sums of the column values to 1</li>
</ul>
</div>
</div>
<div id="outline-container-orgdb4c45c" class="outline-3">
<h3 id="orgdb4c45c">Two</h3>
<div class="outline-text-3" id="text-orgdb4c45c">
<p>
Which of these methods can be used to preprocess text?
</p>
<ul class="org-ul">
<li class="on">
<code>[X]</code> stemming</li>
<li class="on">
<code>[X]</code> Lower-case transformation</li>
<li class="on">
<code>[X]</code> Lemmatization</li>
<li class="on">
<code>[X]</code> Stopword removal</li>
<li class="off">
<code>[ ]</code> Levenshteining</li>
<li class="off">
<code>[ ]</code> plumping</li>
<li class="off">
<code>[ ]</code> plumbing</li>
</ul>
</div>
</div>
<div id="outline-container-orga0899ed" class="outline-3">
<h3 id="orga0899ed">Three</h3>
<div class="outline-text-3" id="text-orga0899ed">
<p>
What is the main purpose of lemmatization and stemming?
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> to remove words which are not useful</li>
<li class="on">
<code>[X]</code> to remove inflectional forms and sometimes derivationally related forms of a word to a common base form</li>
<li class="off">
<code>[ ]</code> To reduce the significance of common words</li>
<li class="off">
<code>[ ]</code> to induce common word amplification standards to the most useful for machine learning algorithms form</li>
</ul>
</div>
</div>
<div id="outline-container-org021da8c" class="outline-3">
<h3 id="org021da8c">Four</h3>
<div class="outline-text-3" id="text-org021da8c">
<p>
To learn Word2Vec embeddings we need:
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> GloVe embeddings</li>
<li class="off">
<code>[ ]</code> Labels for the documents in the corpora</li>
<li class="on">
<code>[X]</code> Labels for each word in the documents in the corpora</li>
<li class="on">
<code>[X]</code> Text corpora</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org0e0c001" class="outline-2">
<h2 id="org0e0c001">Quiz</h2>
<div class="outline-text-2" id="text-org0e0c001">
</div>
<div id="outline-container-orgc214beb" class="outline-3">
<h3 id="orgc214beb">One</h3>
<div class="outline-text-3" id="text-orgc214beb">
<p>
Select true statements about n-grams.
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> Levenshteining should always be applied before computing n-grams (there is no such thing as Levenshteining)</li>
<li class="off">
<code>[ ]</code> n-grams always help increase significance of important words (n-grams are about counts, not importance)</li>
<li class="on">
<code>[X]</code> n-grams features are typically sparse (n-grams count occurrences of words and not every word will be found in every document)</li>
<li class="on">
<code>[X]</code> n-grams can help utilize local context around each word (n-grams encode sequences of words)</li>
</ul>
</div>
</div>
<div id="outline-container-org7a24038" class="outline-3">
<h3 id="org7a24038">Two</h3>
<div class="outline-text-3" id="text-org7a24038">
<p>
Select the true statements.
</p>
<ul class="org-ul">
<li class="on">
<code>[X]</code> Bag of words usually produces longer vectors than Word2Vec (The number of features with BOW is equal to the number of unique words, Word2Vec limit is set beforehand)</li>
<li class="on">
<code>[X]</code> Semantically similar words usually have similar word2vec embeddings</li>
<li class="off">
<code>[ ]</code> You do not need bag of words features in a competition if you have word2vec features (both approaches are useful and can work together)
<ul class="org-ul">
<li class="off">
<code>[ ]</code> The meaning of each value in the Bag of Words matrix is unknown (The meaning of each value is how many times it occurred)</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgf58bb26" class="outline-3">
<h3 id="orgf58bb26">Three</h3>
<div class="outline-text-3" id="text-orgf58bb26">
<p>
Suppose in a new competition we are given a dataset of 2D medical images. We want to extract image descriptors from a hidden layer of a neural network pretrained on the ImageNet dataset. We will then use extracted descriptors to train a simple logistic regression model to classify images from our dataset.
</p>

<p>
We are considering using two networks: ResNet-50 with an ImageNet accuracy of X and VGG-16 with an ImageNet accuracy of Y (X &lt; Y). Select the true statements.
</p>

<ul class="org-ul">
<li class="off">
<code>[ ]</code> With one pretrained CNN model you can get only one vector of descriptors for an image</li>
<li class="off">
<code>[ ]</code> Descriptors from ResNet 50 will always be better than the ones from VG-16 in our pipeline</li>
<li class="on">
<code>[X]</code> It is not clear what descriptors are better on our dataset. We should evaluate both.
<ul class="org-ul">
<li class="off">
<code>[ ]</code> Descriptors from ResNet-50 and VGG-16 are always very similar in cosine distance</li>
<li class="off">
<code>[ ]</code> For any image, descriptors from the last hidden layer of ResNet-50 are the same as the descriptors from the last hidden layer of VGG-16</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org18afcb8" class="outline-3">
<h3 id="org18afcb8">Four</h3>
<div class="outline-text-3" id="text-org18afcb8">
<p>
Data augmentation can be used at (1) train time and (2) test time
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> True, False</li>
<li class="off">
<code>[ ]</code> False, True</li>
<li class="on">
<code>[X]</code> True, True</li>
<li class="off">
<code>[ ]</code> False, False</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgce3e50a" class="outline-2">
<h2 id="orgce3e50a">Links</h2>
<div class="outline-text-2" id="text-orgce3e50a">
</div>
<div id="outline-container-org9232cc7" class="outline-3">
<h3 id="org9232cc7">Text</h3>
<div class="outline-text-3" id="text-org9232cc7">
</div>
<div id="outline-container-orge18959d" class="outline-4">
<h4 id="orge18959d">Bag Of Words</h4>
<div class="outline-text-4" id="text-orge18959d">
<ul class="org-ul">
<li><a href="http://scikit-learn.org/stable/modules/feature_extraction.html">SKlearn on feature extraction</a></li>
<li>
<a href="https://andhint.github.io/machine-learning/nlp/Feature-Extraction-From-Text/">blog post</a> on extracting features from text</li>
</ul>
</div>
</div>
<div id="outline-container-org68c4857" class="outline-4">
<h4 id="org68c4857">Word2Vec</h4>
<div class="outline-text-4" id="text-org68c4857">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/tutorials/representation/word2vec">TensorFlow tutorial</a></li>
<li>
<a href="https://rare-technologies.com/word2vec-tutorial/">Blog post tutorial</a> by the author of gensim</li>
<li><a href="https://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/">Text Classification post</a></li>
<li><a href="https://taylorwhitten.github.io/blog/word2vec">Another introduction</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgae7867c" class="outline-4">
<h4 id="orgae7867c">Natural Language Processing with Python</h4>
<div class="outline-text-4" id="text-orgae7867c">
<ul class="org-ul">
<li><a href="http://www.nltk.org/">nltk</a></li>
<li><a href="https://textblob.readthedocs.io/en/dev/">TextBlob</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgfdeada8" class="outline-3">
<h3 id="orgfdeada8">Images</h3>
<div class="outline-text-3" id="text-orgfdeada8">
</div>
<div id="outline-container-org855838a" class="outline-4">
<h4 id="org855838a">Pre-trained Models</h4>
<div class="outline-text-4" id="text-org855838a">
<ul class="org-ul">
<li><a href="https://keras.io/applications/">Keras</a></li>
<li><a href="https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network_p11">How To use a pre-trained model</a></li>
</ul>
</div>
</div>
<div id="outline-container-org55e6776" class="outline-4">
<h4 id="org55e6776">Fine-Tuning</h4>
<div class="outline-text-4" id="text-org55e6776">
<ul class="org-ul">
<li><a href="https://www.tensorflow.org/hub/tutorials/image_retraining">Re-train a tensorflow image classifier</a></li>
<li><a href="https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html">Fine-tuning deep learning models in keras</a></li>
</ul>
</div>
</div>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/featureextraction-text-images-notes/" rel="tag">featureextraction text images notes</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../first-naive-try/" rel="prev" title="First Naive Try">Previous post</a>
            </li>
            <li class="next">
                <a href="../building-the-training-set/" rel="next" title="Building The Training Set">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2018         <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a><br>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
