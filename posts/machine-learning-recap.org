#+BEGIN_COMMENT
.. title: Machine Learning Recap
.. slug: machine-learning-recap
.. date: 2018-08-04 18:13:44 UTC-07:00
.. tags: basics algorithms
.. category: basics
.. link: 
.. description: A review of the most common machine learning algorithms.
.. type: text
#+END_COMMENT

* The Main Categories
  These are the four main categories of supervised machine learning algorithms that you'll encounter in kaggle competitions.

  - Linear Models
    + sklearn
    + vowpal rabbit (for really large datasets)
  - Tree-Based Models
    + sklearn
    + xgboost: faster than sklearn
  - k-Nearest Neighbors
    + sklearn
  - Neural Networks
* The No Free Lunch Theorem
#+BEGIN_QUOTE
There is no method which outperforms all others for all tasks.
#+END_QUOTE

You cannot assume that an algorithm that did well on one set of data will do well on another. All algorithms have weaknesses, so you have to test multiple algorithms on each data set.
* Summary
  - there is no one algorithm to rule them all
  - Linear models split spaces into two sub-spaces
  - tree-based models spit spaces into boxes
  - kNN relies on measuring the 'closeness' between points
  - Neural Networks provide non-linear decision boundaries

In general the two most powerful methods are *Gradient Boosted Decision Trees* and *Neural Networks*, but this won't always be the case.
