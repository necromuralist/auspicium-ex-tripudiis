#+BEGIN_COMMENT
.. title: First Naive Try
.. slug: first-naive-try
.. date: 2018-08-11 19:37:37 UTC-07:00
.. tags: naive model
.. category: naive
.. link: 
.. description: A first naive model.
.. type: text
#+END_COMMENT

* Imports
#+BEGIN_SRC ipython :session naive :results none
# python standard library
import warnings
import os
import pickle

warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")

# from pypi
import numpy
import pandas
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomTreesRegressor
from tabulate import tabulate

# this project
from helpers.helpers import (
    Helpers,
    DataSource,
    DataKeys,
    Pickles,
    )
#+End_SRC
* Loading the Data

#+BEGIN_SRC ipython :session naive :results none
DataSource = Helpers.unpickle("DataSource")
#+END_SRC

This probably doesn't make sense anymore. Better to just get the random seed and use =train_test_split=, maybe.
#+BEGIN_SRC ipython :session naive :results none
x_train = Helpers.unpickle(Pickles.x_train)
x_test = Helpers.unpickle(Pickles.x_test)
y_train = Helpers.unpickle(Pickles.y_train)
y_test = Helpers.unpickle(Pickles.y_test)
#+END_SRC

#+BEGIN_SRC ipython :session naive :results output raw :exports both
Helpers.print_head(x_train)
#+END_SRC

#+RESULTS:
| date_block_num | shop_id | item_id | item_price | item_name                                                                               | item_category_id | month | year |
|----------------+---------+---------+------------+-----------------------------------------------------------------------------------------+------------------+-------+------|
|             11 |      15 |    1324 |        499 | ARMSTRONG LOUIS  Essential Collection  3CD                                              |               55 |    12 | 2013 |
|             18 |      31 |   19981 |        499 | Толстой Л.Н.  Война и мир  Роман-эпопея  4CD (mp3-CD) (Jewel)                           |               43 |    07 | 2014 |
|             32 |      28 |    7934 |        398 | XOne: Пульт дистанционного управления для Xbox One [6DV-00006]                          |                7 |    09 | 2015 |
|             12 |      43 |   13518 |       1499 | Комплект Прогулки с динозаврами (только для PS Move) [PS3, русская версия] + Wonderbook |               19 |    01 | 2014 |
|             28 |      25 |   19927 |        329 | Таривердиев М. Инструментальные кинохиты (подар. уп.) (mp3-CD) (Jewel)                  |               57 |    05 | 2015 |

* The Linear Model
  What happens if we just use the default linear regression model? The first problem we have is that we have both non-numeric data and categorical data. I think removing the =item_name= variable seems reasonable at this point, since we have unique =item_id= values for each item, although it's possible that some text-mining might reveal something in the names, because this is just a naive approach that will use linear regression.

#+BEGIN_SRC ipython :session naive :results none
del(x_train[DataKeys.name])
#+END_SRC

#+BEGIN_SRC ipython :session naive :results none
regression = linear_model.LinearRegression()
regression.fit(x_train, y_train)
#+END_SRC
