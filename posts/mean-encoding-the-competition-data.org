#+BEGIN_COMMENT
.. title: Mean Encoding The Competition Data
.. slug: mean-encoding-the-competition-data
.. date: 2018-09-23 18:50:28 UTC-07:00
.. tags: assignment competition encoding
.. category: assignment
.. link: 
.. description: Mean encoding applied to the competition data.
.. type: text
#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 1

* Introduction

In this programming assignment you will be working with the /1C/ dataset from the final competition. You are asked to encode the =item_id= in 4 different ways:
 
     1) Via KFold scheme;  
     2) Via Leave-one-out scheme;
     3) Via smoothing scheme;
     4) Via expanding mean scheme.

**You will need to submit** the correlation coefficient between the resulting encoding and the target variable up to 4 decimal places.

* General tips

- Fill NANs in the encoding with =0.3343=.
- Some encoding schemes depend on sorting order, so in order to avoid confusion, please use the following code snippet to construct the data frame. This snippet also implements mean encoding without regularization.

#+BEGIN_SRC python :session encoding :results none
import warnings
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")
#+END_SRC

#+BEGIN_SRC ipython :session encoding :results none
# python standard library
from itertools import product

# pypi
from sklearn.model_selection import StratifiedKFold
import pandas
import numpy

# this course (github)
from hse_graders.assignment_3.grader import Grader

# this project
from kaggler.course.data import Data
#+END_SRC

#+BEGIN_SRC ipython :session encoding :results none
NAN_VALUE = 0.3343
#+END_SRC

* Read In the Data

#+BEGIN_SRC ipython :session encoding :results none
sales = Data().sales_training_data
#+END_SRC

* Aggregate data

Since the competition task is to make a monthly prediction, we need to aggregate the data to montly level before doing any encodings. The following code-cell serves just that purpose.

#+BEGIN_SRC ipython :session encoding :results none
index_cols = ['shop_id', 'item_id', 'date_block_num']
#+END_SRC

For every month we create a grid from all shops/items combinations from that month.

#+BEGIN_SRC ipython :session encoding :results none
grid = [] 
for block_num in sales['date_block_num'].unique():
    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()
    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()
    grid.append(numpy.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))
#+END_SRC

Now turn the grid into a pandas dataframe.

#+BEGIN_SRC ipython :session encoding :results none
grid = pandas.DataFrame(numpy.vstack(grid), columns = index_cols,dtype=numpy.int32)
#+END_SRC

#+BEGIN_SRC ipython :session encoding :results output
print(grid.head())
#+END_SRC

#+RESULTS:
:    shop_id  item_id  date_block_num
: 0       59    22154               0
: 1       59     2552               0
: 2       59     2554               0
: 3       59     2555               0
: 4       59     2564               0

Get the aggregated values for (=shop_id=, =item_id=, and =month=).

#+BEGIN_SRC ipython :session encoding :results none
grouped = sales.groupby(index_cols, as_index=False)
grouped = grouped.item_cnt_day.agg('sum')
#+END_SRC

Fix the column names.

#+BEGIN_SRC ipython :session encoding :results none
grouped.columns = index_cols + ["target"]
#+END_SRC

#+BEGIN_SRC ipython :session encoding :results output
print(grouped.head())
#+END_SRC

#+RESULTS:
:    shop_id  item_id  date_block_num  target
: 0        0       30               1    31.0
: 1        0       31               1    11.0
: 2        0       32               0     6.0
: 3        0       32               1    10.0
: 4        0       33               0     3.0

Join the aggregated data to the grid.

#+BEGIN_SRC ipython :session encoding :results none
all_data = pandas.merge(grid, grouped, how='left', on=index_cols).fillna(0)
#+END_SRC

Sort the data.

#+BEGIN_SRC ipython :session encoding :results none
all_data.sort_values(['date_block_num','shop_id','item_id'], inplace=True)
#+END_SRC

* Mean encodings without regularization

Now that we have done the techinical work, we are ready to actually *mean encode* the desired =item_id= variable. 

Here are two ways to implement mean encoding features *without* any regularization. You can use this code as a starting point to implement regularized techniques. 

** Method 1:  Calculate a mapping: {item_id: target_mean}

#+BEGIN_SRC ipython :session encoding :results none
item_id_target_mean = all_data.groupby('item_id').target.mean()
#+END_SRC

In our non-regularized case we just *map* the computed means to the =item_id='s.

#+BEGIN_SRC ipython :session encoding :results none
all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)
#+END_SRC

** Fill NaNs

#+BEGIN_SRC ipython :session encoding :results none
all_data['item_target_enc'].fillna(NAN_VALUE, inplace=True) 
#+END_SRC

** Print correlation

#+BEGIN_SRC ipython :session encoding :results output raw :exports both
encoded_feature = all_data['item_target_enc'].values
print(numpy.corrcoef(all_data['target'].values, encoded_feature)[0][1])
#+END_SRC

#+RESULTS:
0.48303869886216977

* Method 2

Unlike the  =.target.mean()= function, =transform= will return a dataframe with an index like in =all_data=.
Basically this single line of code is equivalent to the first two lines from of Method 1.

#+BEGIN_SRC ipython :session encoding :results none
all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')
#+END_SRC

** Fill NaNs

#+BEGIN_SRC ipython :session encoding :results none
all_data['item_target_enc'].fillna(NAN_VALUE, inplace=True) 
#+END_SRC

** Print correlation

#+BEGIN_SRC ipython :session encoding :results output raw :exports both
encoded_feature = all_data['item_target_enc'].values
print(numpy.corrcoef(all_data['target'].values, encoded_feature)[0][1])
#+END_SRC

#+RESULTS:
0.48303869886216977


See the printed value? It is the correlation coefficient between the target variable and your new encoded feature. You need to **compute the correlation coefficient** between the encodings that you will implement and **submit those to coursera**.

#+BEGIN_SRC ipython :session encoding :results none
grader = Grader()
#+END_SRC

* 1. KFold scheme

This is Explained starting at 41 seconds into the [[https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization][Regularization lecture]].

First implement the KFold scheme with five folds. Use KFold(5) from sklearn.model_selection. 

 1. Split your data in 5 folds with [[http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html][sklearn.model_selection.KFold]] with ~shuffle=False~ (the default).
 2. Iterate through folds: use all but the current fold to calculate mean target for each level `item_id`, and  fill the current fold.

See the **Method 1** from the example implementation. In particular learn what `map` and pd.Series.map functions do. They are pretty handy in many situations.

#+BEGIN_SRC ipython :session encoding :results none
y_train = all_data["target"].values
folds = StratifiedKFold(y_train, 5, shuffle=True)
column = "item_id"
for training_index, validation_index in folds:
    x_train = all_data.iloc[training_index]
    x_validation = all_data.iloc[validation_index]
    means = x_validation[column].map(x_train.groupby(column).target.mean())
    x_validation[column + "_mean_target"] = means
    # train_new is a dataframe copy we made of the training data
    train_new.iloc[validation_index] = x_validation

train_new.fillna(global_mean, inplace=True)
#+END_SRC

# You will need to compute correlation like that
corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(corr)
grader.submit_tag('KFold_scheme', corr)


# # 2. Leave-one-out scheme

# Now, implement leave-one-out scheme. Note that if you just simply set the number of folds to the number of samples and run the code from the **KFold scheme**, you will probably wait for a very long time. 
# 
# To implement a faster version, note, that to calculate mean target value using all the objects but one *given object*, you can:
# 
# 1. Calculate sum of the target values using all the objects.
# 2. Then subtract the target of the *given object* and divide the resulting value by `n_objects - 1`. 
# 
# Note that you do not need to perform `1.` for every object. And `2.` can be implemented without any `for` loop.
# 
# It is the most convenient to use `.transform` function as in **Method 2**.

# In[ ]:


# YOUR CODE GOES HERE

corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(corr)
grader.submit_tag('Leave-one-out_scheme', corr)


# # 3. Smoothing

# Explained starting at 4:03 of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization).

# Next, implement smoothing scheme with $\alpha = 100$. Use the formula from the first slide in the video and $0.3343$ as `globalmean`. Note that `nrows` is the number of objects that belong to a certain category (not the number of rows in the dataset).

# In[ ]:


# YOUR CODE GOES HERE

corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(corr)
grader.submit_tag('Smoothing_scheme', corr)


# # 4. Expanding mean scheme

# Explained starting at 5:50 of [Regularization video](https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization).

# Finally, implement the *expanding mean* scheme. It is basically already implemented for you in the video, but you can challenge yourself and try to implement it yourself. You will need [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) and [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html) functions from pandas.

# In[ ]:


# YOUR CODE GOES HERE

corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(corr)
grader.submit_tag('Expanding_mean_scheme', corr)


# ## Authorization & Submission
# To submit assignment parts to Cousera platform, please, enter your e-mail and token into variables below. You can generate token on this programming assignment page. Note: Token expires 30 minutes after generation.

# In[ ]:


STUDENT_EMAIL = # EMAIL HERE
STUDENT_TOKEN = # TOKEN HERE
grader.status()


# In[ ]:


grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)

