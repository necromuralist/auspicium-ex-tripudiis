<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Notes on studying kaggle.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Notes on Kaggle</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="https://necromuralist.github.io/Kaggle-Competitions/">
<link rel="next" href="index-3.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script><link rel="prefetch" href="posts/mean-encoding-quiz/" type="text/html">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-default navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://necromuralist.github.io/Kaggle-Competitions/">

                <span id="blog-title">Notes on Kaggle</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li class="active">
<a href=".">The Cloistered Monkey <span class="sr-only">(active)</span></a>
                </li>
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>
                </li>
<li>
<a href="rss.xml">RSS feed</a>

                
            </li>
</ul>
<!-- Google custom search --><form method="get" action="https://www.google.com/search" class="navbar-form navbar-right" role="search">
<div class="form-group">
<input type="text" name="q" class="form-control" placeholder="Search">
</div>
<button type="submit" class="btn btn-primary">
	<span class="glyphicon glyphicon-search"></span>
</button>
<input type="hidden" name="sitesearch" value="https://necromuralist.github.io/Kaggle-Competitions/">
</form>
<!-- End of custom search -->


            <ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/mean-encoding-quiz/" class="u-url">Mean Encoding Quiz</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/mean-encoding-quiz/" rel="bookmark"><time class="published dt-published" datetime="2018-09-28T16:16:59-07:00" title="2018-09-28 16:16">2018-09-28 16:16</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="outline-container-orgc98d90c" class="outline-2">
<h2 id="orgc98d90c">Quiz</h2>
<div class="outline-text-2" id="text-orgc98d90c">
</div>
<div id="outline-container-org7b693c9" class="outline-3">
<h3 id="org7b693c9">One</h3>
<div class="outline-text-3" id="text-org7b693c9">
<p>
What might be an indicator that mean encoding would be useful?
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> a lot of binary variables</li>
<li class="off">
<code>[ ]</code> a learning to rank task</li>
<li class="on">
<code>[X]</code> categorical variables with lots of levels</li>
</ul>
</div>
</div>
<div id="outline-container-org658044b" class="outline-3">
<h3 id="org658044b">Two</h3>
<div class="outline-text-3" id="text-org658044b">
<p>
What is the purpose of regularization in mean encoding?
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> Regularization allows you to make the feature space more sparse?</li>
<li class="on">
<code>[X]</code> Regularization allows us to better utilize mean encoding</li>
<li class="on">
<code>[X]</code> regularization reduces target variable leakage during the construction of mean encodings</li>
</ul>
</div>
</div>
<div id="outline-container-org69dae51" class="outline-3">
<h3 id="org69dae51">Three</h3>
<div class="outline-text-3" id="text-org69dae51">
<p>
What is the correct form of validation when using mean encoding?
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> calculate the mean enocding on all training data, regularize, then varidate on a random validation split</li>
<li class="on">
<code>[X]</code> split the data into training and validation sets, then estimate the encodings on the training data, then apply them to the validation and validate the model on that split</li>
<li class="off">
<code>[ ]</code> Fix the cross-validation split, use that split to calculate mean encodings with cross-validation loop regularization, use the same split to validate the model</li>
</ul>
</div>
</div>
<div id="outline-container-orgd06b2c1" class="outline-3">
<h3 id="orgd06b2c1">Four</h3>
<div class="outline-text-3" id="text-orgd06b2c1">
<p>
Suppose we have a data frame (<code>df</code>) with a categorical variable named <code>item_id</code> and a target variable called <code>target</code>.
We create two different mean encodings:
</p>

<ol class="org-ol">
<li>via df["item<sub>id</sub><sub>encoded1</sub>"] = df.groupby("item<sub>id</sub>")["target"].transform("mean")</li>
<li>Via One Hot Encoding <code>item_id</code>, fitting a linear regression on the encoding and the calculating <code>item_id_encoded2</code> as a prediction from this regression on the same data.</li>

<li class="on">
<code>[X]</code> <code>item_id_encoded1</code> and <code>item_id_encoded2</code> will essentially be the same only if the linear regression was fitted without a regularization</li>
<li class="off">
<code>[ ]</code> <code>item_id_encoded1</code> and <code>item_id_encoded2</code> will be essentially the same</li>
<li class="off">
<code>[ ]</code> <code>item_id_encoded1</code> and <code>item_id_encoded2</code> may differ a lot due to rare categories (nope)</li>
</ol>
</div>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/predicting-the-mean/" class="u-url">Predicting the Mean</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/predicting-the-mean/" rel="bookmark"><time class="published dt-published" datetime="2018-09-24T16:00:05-07:00" title="2018-09-24 16:00">2018-09-24 16:00</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/predicting-the-mean/#org6cc2d0a">Introduction</a></li>
<li><a href="posts/predicting-the-mean/#org3232f35">Imports</a></li>
<li><a href="posts/predicting-the-mean/#org84a4c52">The Data</a></li>
<li><a href="posts/predicting-the-mean/#org1ab5732">Really Naive</a></li>
</ul>
</div>
</div>

<div id="outline-container-org6cc2d0a" class="outline-2">
<h2 id="org6cc2d0a">Introduction</h2>
<div class="outline-text-2" id="text-org6cc2d0a">
<p>
Since the competition is going to be scored using the Root Mean Square Error I'll make a baseline prediction by using the mean of the sales figures.
</p>
</div>
</div>
<div id="outline-container-org3232f35" class="outline-2">
<h2 id="org3232f35">Imports</h2>
<div class="outline-text-2" id="text-org3232f35">
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">"numpy.dtype size changed"</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">"numpy.ufunc size changed"</span><span class="p">)</span>
</pre></div>

<div class="highlight"><pre><span></span># python standard library
from pathlib import Path

# from pypi
from tabulate import tabulate
import pandas

# this project
from kaggler.course.data import Data
from kaggler.helpers.printing import print_table
</pre></div>
</div>
</div>

<div id="outline-container-org84a4c52" class="outline-2">
<h2 id="org84a4c52">The Data</h2>
<div class="outline-text-2" id="text-org84a4c52">
<div class="highlight"><pre><span></span>data = Data()
training = data.sales_training_data
</pre></div>

<div class="highlight"><pre><span></span>print_table(training.head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">date</th>
<th scope="col" class="org-right">date_block_num</th>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
<th scope="col" class="org-right">item_price</th>
<th scope="col" class="org-right">item_cnt_day</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">02.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">59</td>
<td class="org-right">22154</td>
<td class="org-right">999</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-right">03.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2552</td>
<td class="org-right">899</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-right">05.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2552</td>
<td class="org-right">899</td>
<td class="org-right">-1</td>
</tr>
<tr>
<td class="org-right">06.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2554</td>
<td class="org-right">1709.05</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-right">15.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2555</td>
<td class="org-right">1099</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org1ab5732" class="outline-2">
<h2 id="org1ab5732">Really Naive</h2>
<div class="outline-text-2" id="text-org1ab5732">
<p>
I was originally just going by average per month for the whole data set but that turns out to be too big, especially since it gets capped at 20. Furthermore, when you look at the test-data it has one ID column but the contest description says that you have to predict shop and item sales for the next month, what is the test-set again?
</p>

<p>
Re-reading <a href="https://www.kaggle.com/c/competitive-data-science-final-project/data">the data description</a> I just noticed that it says that the ID in the test set represents a (shop ID, item ID) tuple. Where is this defined?
</p>

<div class="highlight"><pre><span></span>test = data.test_data
print_table(test.head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">ID</th>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">5</td>
<td class="org-right">5037</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-right">5</td>
<td class="org-right">5320</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-right">5</td>
<td class="org-right">5233</td>
</tr>
<tr>
<td class="org-right">3</td>
<td class="org-right">5</td>
<td class="org-right">5232</td>
</tr>
<tr>
<td class="org-right">4</td>
<td class="org-right">5</td>
<td class="org-right">5268</td>
</tr>
</tbody>
</table>
<p>
Okay, so it looks like the test-set has the shop and item IDs, but when you make the submission you just dump them. Interesting. So our average needs to be an average for an item in a certain shop for a month.
</p>

<div class="highlight"><pre><span></span>training["ID"] = list(zip(training.shop_id, training.item_id))
print_table(training.head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-left">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">date</th>
<th scope="col" class="org-right">date_block_num</th>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
<th scope="col" class="org-right">item_price</th>
<th scope="col" class="org-right">item_cnt_day</th>
<th scope="col" class="org-left">ID</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">02.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">59</td>
<td class="org-right">22154</td>
<td class="org-right">999</td>
<td class="org-right">1</td>
<td class="org-left">(59, 22154)</td>
</tr>
<tr>
<td class="org-right">03.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2552</td>
<td class="org-right">899</td>
<td class="org-right">1</td>
<td class="org-left">(25, 2552)</td>
</tr>
<tr>
<td class="org-right">05.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2552</td>
<td class="org-right">899</td>
<td class="org-right">-1</td>
<td class="org-left">(25, 2552)</td>
</tr>
<tr>
<td class="org-right">06.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2554</td>
<td class="org-right">1709.05</td>
<td class="org-right">1</td>
<td class="org-left">(25, 2554)</td>
</tr>
<tr>
<td class="org-right">15.01.2013</td>
<td class="org-right">0</td>
<td class="org-right">25</td>
<td class="org-right">2555</td>
<td class="org-right">1099</td>
<td class="org-right">1</td>
<td class="org-left">(25, 2555)</td>
</tr>
</tbody>
</table>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/mean-encoding-the-competition-data/" class="u-url">Mean Encoding The Competition Data</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/mean-encoding-the-competition-data/" rel="bookmark"><time class="published dt-published" datetime="2018-09-23T18:50:28-07:00" title="2018-09-23 18:50">2018-09-23 18:50</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/mean-encoding-the-competition-data/#orgd9ea2a0">Introduction</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#org6e1aa15">General tips</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#orgd0b5abe">Read In the Data</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#orgecb7c6c">The Motivation</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#orgccff9c2">Aggregate data</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#org2a2326e">Mean encodings without regularization</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#org796211e">Method 2</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#orge83419d">1. KFold scheme</a></li>
<li><a href="posts/mean-encoding-the-competition-data/#orgc21ea92">2. Leave-one-out scheme</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgd9ea2a0" class="outline-2">
<h2 id="orgd9ea2a0">Introduction</h2>
<div class="outline-text-2" id="text-orgd9ea2a0">
<p>
In this programming assignment you will be working with the <a href="https://www.kaggle.com/c/competitive-data-science-final-project/data">1C dataset</a> from the final competition. You are asked to encode the <code>item_id</code> in 4 different ways:
</p>

<ol class="org-ol">
<li>Via KFold scheme;</li>
<li>Via Leave-one-out scheme;</li>
<li>Via smoothing scheme;</li>
<li>Via expanding mean scheme.</li>
</ol>
<p>
<b><b>You will need to submit</b></b> the correlation coefficient between the resulting encoding and the target variable up to 4 decimal places.
</p>
</div>
</div>

<div id="outline-container-org6e1aa15" class="outline-2">
<h2 id="org6e1aa15">General tips</h2>
<div class="outline-text-2" id="text-org6e1aa15">
<ul class="org-ul">
<li>Fill NANs in the encoding with <code>0.3343</code>.</li>
<li>Some encoding schemes depend on sorting order, so in order to avoid confusion, please use the following code snippet to construct the data frame. This snippet also implements mean encoding without regularization.</li>
</ul>
<div class="highlight"><pre><span></span>NAN_VALUE = 0.3343
</pre></div>

<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">"numpy.dtype size changed"</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">"numpy.ufunc size changed"</span><span class="p">)</span>
</pre></div>

<div class="highlight"><pre><span></span># python standard library
from itertools import product

from sklearn.model_selection import KFold
import pandas
import numpy

# this course (github)
from hse_graders.assignment_3.grader import Grader

# this project
from kaggler.course.data import Data
from kaggler.helpers.printing import print_table
</pre></div>

<div class="highlight"><pre><span></span>NAN_VALUE = 0.3343
</pre></div>
</div>
</div>

<div id="outline-container-orgd0b5abe" class="outline-2">
<h2 id="orgd0b5abe">Read In the Data</h2>
<div class="outline-text-2" id="text-orgd0b5abe">
<div class="highlight"><pre><span></span>sales = Data().sales_training_data
</pre></div>
</div>
</div>

<div id="outline-container-orgecb7c6c" class="outline-2">
<h2 id="orgecb7c6c">The Motivation</h2>
<div class="outline-text-2" id="text-orgecb7c6c">
<p>
The idea behind this is that we want to convert a categorical value (the item ID) into a numeric one so that we can use non-tree-based methods. But we already have <a href="https://en.wikipedia.org/wiki/One-hot">One Hot Encoding</a>, so why do we need this? Well, lets look at how many items we need to encode.
</p>

<div class="highlight"><pre><span></span>print("{:,}".format(len(sales.item_id.unique())))
</pre></div>

<pre class="example">
21,807

</pre>

<p>
This means we're going to have to add almost twenty-two thousand columns to your table, which brings up the <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">Curse of Dimensionality</a> - adding this many columns means we're going to need a lot more data for our model to work and will increase our computation time significantly. Using Mean Encoding means that we will only have to add one column, simplifying our computation and reducing the amount of data we need to fit the model.
</p>
</div>
</div>

<div id="outline-container-orgccff9c2" class="outline-2">
<h2 id="orgccff9c2">Aggregate data</h2>
<div class="outline-text-2" id="text-orgccff9c2">
<p>
Since the competition task is to make a monthly prediction, we need to aggregate the data to the monthly level before doing any encodings. The following code-cells do that for us.
</p>

<div class="highlight"><pre><span></span>group_by_columns = ['shop_id', 'item_id', 'date_block_num']
</pre></div>

<p>
For every month we create a grid from all shops/items combinations for that month. This uses <a href="https://docs.python.org/3/library/itertools.html#itertools.product">itertools.product</a> which creates the cartesian product of the collections it's given.
</p>

<div class="highlight"><pre><span></span>grid = [] 
for block_num in sales['date_block_num'].unique():
    block = sales[sales['date_block_num']==block_num]
    cur_shops = block['shop_id'].unique()
    cur_items = block['item_id'].unique()
    grid.append(numpy.array(list(product(*[cur_shops, cur_items, [block_num]])), dtype='int32'))
</pre></div>

<p>
Now turn the grid into a pandas dataframe.
</p>

<div class="highlight"><pre><span></span>grid = pandas.DataFrame(numpy.vstack(grid), columns=group_by_columns, dtype=numpy.int32)
</pre></div>

<div class="highlight"><pre><span></span>print_table(grid.head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
<th scope="col" class="org-right">date_block_num</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">59</td>
<td class="org-right">22154</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2552</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2554</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2555</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2564</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span>print(grid.shape)
</pre></div>

<pre class="example">
(10913850, 3)

</pre>

<p>
The grid has all the items sold by each shop for each date-block. The number of rows isn't just \(\textit{shops} \times \textit{items} \times \textit{date-blocks}\) because not every shop is in every date-block and not every shop sold every item (or even the same items every block).
</p>

<p>
Now we will use <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html">groupby</a> to group the data by <code>shop_id</code>, <code>item_id</code>, and <i>month</i> (<code>date_block_num</code>) and then get the aggregated summed values for the item count per day (we're going to sum up the items sold per day to get a value for the month) and rename the summed item count column to <code>target</code>.
</p>

<div class="highlight"><pre><span></span>grouped = sales.groupby(group_by_columns, as_index=False)
grouped = grouped["item_cnt_day"].sum()
grouped = grouped.rename(dict(item_cnt_day="target"), axis="columns")
</pre></div>

<div class="highlight"><pre><span></span>print_table(grouped.head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
<th scope="col" class="org-right">date_block_num</th>
<th scope="col" class="org-right">target</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">30</td>
<td class="org-right">1</td>
<td class="org-right">31</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">31</td>
<td class="org-right">1</td>
<td class="org-right">11</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">32</td>
<td class="org-right">0</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">32</td>
<td class="org-right">1</td>
<td class="org-right">10</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">33</td>
<td class="org-right">0</td>
<td class="org-right">3</td>
</tr>
</tbody>
</table>
<p>
Now join the aggregated data to the grid (with <a href="https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging">merge</a>).
</p>

<div class="highlight"><pre><span></span>all_data = pandas.merge(grid, grouped, how='left', on=group_by_columns).fillna(0)
</pre></div>

<div class="highlight"><pre><span></span>print_table(all_data.head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
<th scope="col" class="org-right">date_block_num</th>
<th scope="col" class="org-right">target</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">59</td>
<td class="org-right">22154</td>
<td class="org-right">0</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2552</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2554</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2555</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">59</td>
<td class="org-right">2564</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>
<p>
Sort the data by the month, shop, and item.
</p>

<div class="highlight"><pre><span></span>all_data.sort_values(['date_block_num','shop_id','item_id'], inplace=True)
</pre></div>

<div class="highlight"><pre><span></span>print_table(all_data.head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
<th scope="col" class="org-right">date_block_num</th>
<th scope="col" class="org-right">target</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">19</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">27</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">28</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">29</td>
<td class="org-right">0</td>
<td class="org-right">0</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">32</td>
<td class="org-right">0</td>
<td class="org-right">6</td>
</tr>
</tbody>
</table>
<p>
When we compare <code>all_data</code> to <code>grouped</code>, the difference might not be so obvious, they have the same columns and look pretty similar, but if you look at the <code>all_data.target</code> column you can see that there's a lot of 0s. That's because <code>grouped</code> only has the cases where there were sales but <code>all_data</code> had cases where there weren't any sales for a particular (<code>shop_id</code>, <code>item_id</code>, <code>date_block_num</code>) combination, so it filled in the 0's.
</p>

<div class="highlight"><pre><span></span>print("{:,}".format(all_data.shape[0] - grouped.shape[0]))
</pre></div>

<pre class="example">
9,304,726

</pre>

<p>
You can see that <code>all_data</code> had over 9 million more rows than grouped did.
</p>

<div class="highlight"><pre><span></span>print(grouped[(grouped.shop_id==0) &amp; (grouped.item_id==19) &amp; (grouped.date_block_num==0)])
</pre></div>

<pre class="example">
Empty DataFrame
Columns: [shop_id, item_id, date_block_num, target]
Index: []

</pre>

<p>
And <code>grouped</code> didn't have any entry for the first item in the previous <code>all_data</code> head-table, which is why the target value is 0.
</p>
</div>
</div>

<div id="outline-container-org2a2326e" class="outline-2">
<h2 id="org2a2326e">Mean encodings without regularization</h2>
<div class="outline-text-2" id="text-org2a2326e">
<p>
Now that we have done the technical work, we are ready to actually <b>mean encode</b> the desired <code>item_id</code> variable. 
</p>

<p>
Here are two ways to implement mean encoding features <b>without</b> any regularization. You can use this code as a starting point to implement regularized techniques. 
</p>
</div>

<div id="outline-container-org82a9ee8" class="outline-3">
<h3 id="org82a9ee8">Method 1:  Calculate a mapping: {item_id: target_mean}</h3>
<div class="outline-text-3" id="text-org82a9ee8">
<p>
First we're going to calculate the mean count for each item.
</p>

<div class="highlight"><pre><span></span>item_id_target_mean = all_data.groupby('item_id').target.mean()
</pre></div>

<p>
In our non-regularized case we just <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html">map</a> the computed means to the <code>item_id</code>'s. 
</p>

<div class="highlight"><pre><span></span>all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)
</pre></div>

<p>
In our case we are mapping a series (<code>item_id_target_mean</code>) to a column <code>item_id</code> in a data frame <code>all_data</code>. Wherever an item in the <code>item_id</code> column matches the index of our <code>item_id_target_mean</code> Series it will replace the item with the value in the <code>item_id_target_mean</code> that matches the index.
</p>

<p>
Here's an example. Let's look at the head of the <code>item_id_target_mean</code> Series.
</p>

<div class="highlight"><pre><span></span>print_table(dict(target_mean=item_id_target_mean.head()), showindex=True)
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right"> </th>
<th scope="col" class="org-right">target_mean</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0.02</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-right">0.0238095</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-right">0.019802</td>
</tr>
<tr>
<td class="org-right">3</td>
<td class="org-right">0.019802</td>
</tr>
<tr>
<td class="org-right">4</td>
<td class="org-right">0.02</td>
</tr>
</tbody>
</table>
<p>
So, let's look at index 1 - its value is <i>0.0238095</i> so this mean we would expect that all the items with ID 1 would also have this value in the <code>item_target_enc</code> column. Let's double-check this.
</p>

<div class="highlight"><pre><span></span>print_table(all_data[all_data.item_id==1].head())
</pre></div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">shop_id</th>
<th scope="col" class="org-right">item_id</th>
<th scope="col" class="org-right">date_block_num</th>
<th scope="col" class="org-right">target</th>
<th scope="col" class="org-right">item_target_enc</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">2</td>
<td class="org-right">1</td>
<td class="org-right">15</td>
<td class="org-right">0</td>
<td class="org-right">0.0238095</td>
</tr>
<tr>
<td class="org-right">3</td>
<td class="org-right">1</td>
<td class="org-right">15</td>
<td class="org-right">0</td>
<td class="org-right">0.0238095</td>
</tr>
<tr>
<td class="org-right">4</td>
<td class="org-right">1</td>
<td class="org-right">15</td>
<td class="org-right">0</td>
<td class="org-right">0.0238095</td>
</tr>
<tr>
<td class="org-right">5</td>
<td class="org-right">1</td>
<td class="org-right">15</td>
<td class="org-right">0</td>
<td class="org-right">0.0238095</td>
</tr>
<tr>
<td class="org-right">6</td>
<td class="org-right">1</td>
<td class="org-right">15</td>
<td class="org-right">0</td>
<td class="org-right">0.0238095</td>
</tr>
</tbody>
</table>
<p>
It looks right. Let's make sure.
</p>

<div class="highlight"><pre><span></span>assert all(all_data[all_data.item_id==1] == 0.0238095)
</pre></div>

<p>
Well, this wasn't exhaustive but at least that one item checks out.
</p>
</div>
</div>

<div id="outline-container-org2c7b0be" class="outline-3">
<h3 id="org2c7b0be">Fill NaNs</h3>
<div class="outline-text-3" id="text-org2c7b0be">
<p>
We're given the value to fill in for the missing entries (<i>0.3343</i>) without explanation. I don't really know where it comes from. It's around, but not exactly the 84% percentile, but, anyway, let's use it (actually, if you check it there aren't any NaN values, curious).
</p>

<div class="highlight"><pre><span></span>print(all_data.item_target_enc.hasnans)
</pre></div>

<pre class="example">
False

</pre>

<p>
So this next line doesn't seem to do anything, but is part of the given code.
</p>

<div class="highlight"><pre><span></span>all_data['item_target_enc'].fillna(NAN_VALUE, inplace=True) 
</pre></div>
</div>
</div>

<div id="outline-container-orgee20667" class="outline-3">
<h3 id="orgee20667">Print correlation</h3>
<div class="outline-text-3" id="text-orgee20667">
<p>
Now we need to calculate the <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html">Pearson Correlation</a> between our calculated mean and the target values. This <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">value</a> ranges from -1 to 1 and represents how much of a linear correlation there is between two variables. Negative one means they are completely negatively correlated and positive one means they are completely positively correlated.
</p>

<div class="highlight"><pre><span></span>encoded_feature = all_data['item_target_enc'].values
first_correlation = numpy.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(first_correlation)
</pre></div>

<pre class="example">
0.48303869886216977

</pre>

<p>
Since our value is between 0 and 1 it does describe the target to some degree, albeit not perfectly.
</p>
</div>
</div>
</div>

<div id="outline-container-org796211e" class="outline-2">
<h2 id="org796211e">Method 2</h2>
<div class="outline-text-2" id="text-org796211e">
<p>
Unlike the  <code>.target.mean()</code> function, <code>transform</code> will return a dataframe with an index like in <code>all_data</code>.
Basically this single line of code is equivalent to the first lines from of Method 1.
</p>

<div class="highlight"><pre><span></span>all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')
</pre></div>
</div>

<div id="outline-container-org970fd8c" class="outline-3">
<h3 id="org970fd8c">Fill NaNs</h3>
<div class="outline-text-3" id="text-org970fd8c">
<div class="highlight"><pre><span></span>all_data['item_target_enc'].fillna(NAN_VALUE, inplace=True) 
</pre></div>
</div>
</div>

<div id="outline-container-org43843f1" class="outline-3">
<h3 id="org43843f1">Print correlation</h3>
<div class="outline-text-3" id="text-org43843f1">
<div class="highlight"><pre><span></span>encoded_feature = all_data['item_target_enc'].values
second_correlation = numpy.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(second_correlation)
print(abs(first_correlation - second_correlation))
</pre></div>

<pre class="example">
0.48303869886216977
0.0

</pre>

<p>
See the printed value? It is the correlation coefficient between the target variable and your new encoded feature. You need to <b><b>compute the correlation coefficient</b></b> between the encodings that you will implement and <b><b>submit those to coursera</b></b>.
</p>

<div class="highlight"><pre><span></span>grader = Grader()
</pre></div>
</div>
</div>
</div>

<div id="outline-container-orge83419d" class="outline-2">
<h2 id="orge83419d">1. KFold scheme</h2>
<div class="outline-text-2" id="text-orge83419d">
<p>
This is Explained starting at 41 seconds into the <a href="https://www.coursera.org/learn/competitive-data-science/lecture/LGYQ2/regularization">Regularization lecture</a>.
</p>

<p>
First implement the KFold scheme with five folds. Use KFold(5) from sklearn.model_selection. 
</p>

<ol class="org-ol">
<li>Split your data in 5 folds with <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html">sklearn.model_selection.KFold</a> with <code>shuffle=False</code> (the default).</li>
<li>Iterate through folds: use all but the current fold to calculate mean target for each level `item_id`, and  fill the current fold.</li>
</ol>
<p>
See the <b><b>Method 1</b></b> from the example implementation. In particular learn what `map` and <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html">pandas.Series.map</a> functions do. They are pretty handy in many situations.
</p>

<div class="highlight"><pre><span></span>folder = KFold(n_splits=5, shuffle=False)
column = "item_id"
encoded_column = column + "_mean_target"
train_new = pandas.DataFrame(index=all_data.index, columns=all_data.columns)
train_new[encoded_column] = numpy.nan
for training_index, validation_index in folder.split(all_data):
    x_train = all_data.iloc[training_index].copy()
    x_validation = all_data.iloc[validation_index].copy()
    means = x_validation[column].map(x_train.groupby(column).target.mean())
    x_validation[encoded_column] = means
    # train_new is a dataframe copy we made of the training data
    train_new.iloc[validation_index] = x_validation
train_new.fillna(NAN_VALUE, inplace=True)
</pre></div>

<div class="highlight"><pre><span></span>encoded_feature = train_new.item_id_mean_target.values
</pre></div>

<div class="highlight"><pre><span></span>corr = numpy.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(corr)
grader.submit_tag('KFold_scheme', corr)
</pre></div>
</div>
</div>

<div id="outline-container-orgc21ea92" class="outline-2">
<h2 id="orgc21ea92">2. Leave-one-out scheme</h2>
<div class="outline-text-2" id="text-orgc21ea92">
<p>
Now, implement leave-one-out scheme. Note that if you just simply set the number of folds to the number of samples and run the code from the <b><b>KFold scheme</b></b>, you will probably wait for a very long time. 
</p>

<p>
To implement a faster version, note that to calculate the mean target value using all the objects but one <b>given object</b>, you can:
</p>

<ol class="org-ol">
<li>Calculate the sum of the target values using all the objects.</li>
<li>Then subtract the target of the <b>given object</b> and divide the resulting value by <code>n_objects - 1</code>.</li>
</ol>
<p>
Note that you do not need to perform step 1 for every object. And step 2 can be implemented without any <code>for</code> loop.
</p>

<p>
It will be most convenient to use the `.transform` function as in <b><b>Method 2</b></b>.
</p>

<div class="highlight"><pre><span></span>summed = all_data.groupby('item_id')['target'].transform('sum')
total_sum = summed.sum()
one_less = len(summed) - 1

left_out = (total_sum - summed)/one_less
</pre></div>

<pre class="example">
-0.47032519950821283
Current answer for task Leave-one-out_scheme is: -0.47032519950821283

</pre>


<p>
corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(corr)
grader.submit_tag('Smoothing_scheme', corr)
</p>


<p>
corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]
print(corr)
grader.submit_tag('Expanding_mean_scheme', corr)
</p>


<p>
STUDENT_EMAIL = # EMAIL HERE
STUDENT_TOKEN = # TOKEN HERE
grader.status()
</p>


<p>
grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)
</p>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/mean-encoding/" class="u-url">Mean Encoding</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/mean-encoding/" rel="bookmark"><time class="published dt-published" datetime="2018-09-23T17:56:27-07:00" title="2018-09-23 17:56">2018-09-23 17:56</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/mean-encoding/#org981d2b2">Mean Encoding</a></li>
<li><a href="posts/mean-encoding/#org8c19d2a">Regularization</a></li>
<li><a href="posts/mean-encoding/#orgdd01022">Generalizations and Extensions</a></li>
<li><a href="posts/mean-encoding/#orgc74a70d">Summary</a></li>
</ul>
</div>
</div>

<div id="outline-container-org981d2b2" class="outline-2">
<h2 id="org981d2b2">Mean Encoding</h2>
<div class="outline-text-2" id="text-org981d2b2">
</div>
<div id="outline-container-org9189ad0" class="outline-3">
<h3 id="org9189ad0">Introduction</h3>
<div class="outline-text-3" id="text-org9189ad0">
<ul class="org-ul">
<li>also called target encoding and likelihood encoding</li>
</ul>
<p>
It is a way to encode a categorical feature. Uses the fraction of times the feature is 1 out of all the times the feature is in the data set (for binary classification).
</p>
</div>
<div id="outline-container-orgf79820e" class="outline-4">
<h4 id="orgf79820e">Why does it work?</h4>
<div class="outline-text-4" id="text-orgf79820e">
<p>
Unlike regular encoding, which has no real meaning to the labels, mean encoding imposes an ordering. This allows you to reduce your loss while using shorter trees.
</p>
</div>
</div>
<div id="outline-container-org0754e80" class="outline-4">
<h4 id="org0754e80">How do you calculate it?</h4>
<div class="outline-text-4" id="text-org0754e80">
<p>
There are multiple ways.
</p>
<ul class="org-ul">
<li>Likelihood = \(\frac{count of ones}/{total count}\) = mean(target)</li>
<li>Weight of evidence = \(\ln\left(\frac{count of ones}{count of zeros}\right)\)</li>
<li>Count = sum(target) = count of ones</li>
<li>Diff = count of ones - count of zeros</li>
</ul>
</div>
</div>
<div id="outline-container-org5fce97b" class="outline-4">
<h4 id="org5fce97b">When does it fail?</h4>
<div class="outline-text-4" id="text-org5fce97b">
<p>
If you have lots of feature instances with few cases it will tend to overfit.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org8c19d2a" class="outline-2">
<h2 id="org8c19d2a">Regularization</h2>
<div class="outline-text-2" id="text-org8c19d2a">
</div>
<div id="outline-container-orgda28dd3" class="outline-3">
<h3 id="orgda28dd3">Four Types</h3>
<div class="outline-text-3" id="text-orgda28dd3">
<ul class="org-ul">
<li>Cross-validation loop inside the training data</li>
<li>Smoothing</li>
<li>Adding random noise</li>
<li>Sorting and calculating the expanding mean</li>
</ul>
</div>
</div>
<div id="outline-container-orgde6b1ee" class="outline-3">
<h3 id="orgde6b1ee">Cross Validation</h3>
<div class="outline-text-3" id="text-orgde6b1ee">
<ul class="org-ul">
<li>Usually 4 or 5 folds are enough</li>
<li>Need to watch out for extreme cases like leave-out-one (LOO)</li>
</ul>
<p>
Here's an example of this method using sklearn.
</p>

<div class="highlight"><pre><span></span><span class="n">y_train</span> <span class="o">=</span> <span class="n">training</span><span class="p">[</span><span class="s2">"target"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">folds</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">training_index</span><span class="p">,</span> <span class="n">validation_index</span> <span class="ow">in</span> <span class="n">folds</span><span class="p">:</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">training_index</span><span class="p">]</span>
    <span class="n">x_validation</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">validation_index</span><span class="p">]</span>
    <span class="c1"># 'columns' is a list of columns to encode</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
	<span class="n">means</span> <span class="o">=</span> <span class="n">x_validation</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">column</span><span class="p">)</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
	<span class="n">x_validation</span><span class="p">[</span><span class="n">coulmn</span> <span class="o">+</span> <span class="s2">"_mean_target"</span><span class="p">]</span> <span class="o">=</span> <span class="n">means</span>
    <span class="c1"># train_new is a dataframe copy we made of the training data</span>
    <span class="n">train_new</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">value_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_validation</span>

<span class="n">global_mean</span> <span class="o">=</span> <span class="n">training</span><span class="p">[</span><span class="s2">"target"</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># replace nans with the global mean</span>
<span class="n">train_new</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">global_mean</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div id="outline-container-org59aad2f" class="outline-3">
<h3 id="org59aad2f">Smoothing</h3>
<div class="outline-text-3" id="text-org59aad2f">
<p>
Use a value \(\alpha\) to control the amount of regularization. This isn't a regularization method in and of itself, you use it with other methods.
</p>

<p>
\[
\frac{mean(targte) \times n_{rows} + \textit{global mean} \times \alpha}{n_{rows} + \alpha}
\]
</p>
</div>
</div>

<div id="outline-container-orgfdf906f" class="outline-3">
<h3 id="orgfdf906f">Noise</h3>
<div class="outline-text-3" id="text-orgfdf906f">
<p>
Adding noise degrades the quality of the encoding in the training data. This is usually used with <i>leave-one-out</i> encoding to prevent overfitting. You have to figure out how much noise to add through experimentation.
</p>
</div>
</div>
<div id="outline-container-org8d98283" class="outline-3">
<h3 id="org8d98283">Expanding Mean</h3>
<div class="outline-text-3" id="text-org8d98283">
<p>
This introduces the least amount of leakage from the target variable and doesn't require hyper-parameters for you to tune. The downside is that the encoding quality is irregular. There is a built-in implementation in the <code>CatBoost</code> library.
</p>

<p>
Here's a pandas implementation.
</p>

<div class="highlight"><pre><span></span><span class="n">cumulative_sum</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">column</span><span class="p">)[</span><span class="s2">"target"</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span> <span class="o">-</span> <span class="n">training</span><span class="p">[</span><span class="s2">"target"</span><span class="p">]</span>
<span class="n">cumulative_count</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">column</span><span class="p">)</span><span class="o">.</span><span class="n">cumcount</span><span class="p">()</span>
<span class="n">train_new</span><span class="p">[</span><span class="n">column</span> <span class="o">+</span> <span class="s2">"_mean_target"</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumulative_sum</span><span class="o">/</span><span class="n">cumulative_count</span>
</pre></div>
</div>
</div>

<div id="outline-container-org6d57dc7" class="outline-3">
<h3 id="org6d57dc7">Which one should you use?</h3>
<div class="outline-text-3" id="text-org6d57dc7">
<p>
Cross Validation Loops and Expanding Means are the most practical to use.
</p>
</div>
</div>
</div>
<div id="outline-container-orgdd01022" class="outline-2">
<h2 id="orgdd01022">Generalizations and Extensions</h2>
<div class="outline-text-2" id="text-orgdd01022">
</div>
<div id="outline-container-org187f583" class="outline-3">
<h3 id="org187f583">Regression and Multiclass</h3>
</div>
</div>
<div id="outline-container-orgc74a70d" class="outline-2">
<h2 id="orgc74a70d">Summary</h2>
<div class="outline-text-2" id="text-orgc74a70d">
</div>
<div id="outline-container-orgb189648" class="outline-3">
<h3 id="orgb189648">Advantages</h3>
<div class="outline-text-3" id="text-orgb189648">
<ul class="org-ul">
<li>Compact transformation of categorical variables</li>
<li>Powerful basis for feature engineering</li>
</ul>
</div>
</div>
<div id="outline-container-org388894b" class="outline-3">
<h3 id="org388894b">Disadvantages</h3>
<div class="outline-text-3" id="text-org388894b">
<ul class="org-ul">
<li>Needs careful validation, it's easy to overfit</li>
<li>Only certain data sets will show a significant improvement from using it</li>
</ul>
</div>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/optimizing-classification-metrics/" class="u-url">Optimizing Classification Metrics</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/optimizing-classification-metrics/" rel="bookmark"><time class="published dt-published" datetime="2018-09-23T15:10:09-07:00" title="2018-09-23 15:10">2018-09-23 15:10</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="outline-container-org9dc917b" class="outline-2">
<h2 id="org9dc917b">Introduction</h2>
<div class="outline-text-2" id="text-org9dc917b">
<p>
The <i>target metric</i> is what the competition scores you on, but it isn't always the easiest metric to tune your model on. Sometimes you need to pick and <i>optimization metric</i> to tune your model that isn't exactly the same but works well enough.
</p>
</div>
</div>
<div id="outline-container-orgb733e2f" class="outline-2">
<h2 id="orgb733e2f">LogLoss</h2>
<div class="outline-text-2" id="text-orgb733e2f">
<p>
To optimize log-loss you just have to match it to the right model.
</p>
<ul class="org-ul">
<li>Tree Based: XGBoost, LightGBM</li>
<li>Linear: sklearn.&lt;something&gt;Regression, sklearn.SGDRegressor, Vowpal Wabbit</li>
<li>Neural Nets: PyTorch, Keras, Tensorflow, etc.</li>
</ul>
<p>
Random Forests turn out to do poorly with Log Loss.
</p>
</div>
<div id="outline-container-org89db9fa" class="outline-3">
<h3 id="org89db9fa">Probability Calibration</h3>
<div class="outline-text-3" id="text-org89db9fa">
<p>
If you take all the rows with the same score, then the fraction of them that have a class of 1 should match the score (so if they all have a score of 0.8, then 80% of them should be 1 and 20% should be 0). If the fraction is off, then you need to calibrate the probabilities. To do this take your model and then send its outputs to a model that does better with Log Loss. So if you want to use a Random Forest, you would train your model using AUC as the metric then use the predictions to train another model like a neural net and have it use Log Loss as the metric.
</p>
</div>
<div id="outline-container-org336306c" class="outline-4">
<h4 id="org336306c">Platt Scaling</h4>
<div class="outline-text-4" id="text-org336306c">
<p>
Fit a Logistic Regression to your predictions
</p>
</div>
</div>
<div id="outline-container-org636f8a8" class="outline-4">
<h4 id="org636f8a8">Isotonic Regression</h4>
<div class="outline-text-4" id="text-org636f8a8">
<p>
Fit an Isotonic Regression to your predictions
</p>
</div>
</div>
<div id="outline-container-orgf6afab3" class="outline-4">
<h4 id="orgf6afab3">Stacking</h4>
<div class="outline-text-4" id="text-orgf6afab3">
<p>
Fit XGBoost or a neural net to your predictions
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgb75ed53" class="outline-2">
<h2 id="orgb75ed53">Accuracy</h2>
<div class="outline-text-2" id="text-orgb75ed53">
<p>
Accuracy is a difficult metric to optimize because it isn't differentiable. To optimize the accuracy metric you need to use a different metric (a proxy metric) like log-loss and then tune the threshold.
</p>
</div>
</div>

<div id="outline-container-org87b89a4" class="outline-2">
<h2 id="org87b89a4">Area Under the Curve (AUC)</h2>
<div class="outline-text-2" id="text-org87b89a4">
<p>
Some models work with it so if you can choose one of these models.
</p>
<ul class="org-ul">
<li>Tree-Based: XGBoost, LightGBM</li>
<li>Linear: (don't use)</li>
<li>Neural Nets: PyTorch, Keras, TensorFlow (but not by default)</li>
</ul>
<p>
In practice you can optimize the model to log-loss.
</p>
</div>
</div>
<div id="outline-container-orgb8d2c5a" class="outline-2">
<h2 id="orgb8d2c5a">Quadratic Weighted Kappa</h2>
<div class="outline-text-2" id="text-orgb8d2c5a">
<ol class="org-ol">
<li>Optimize on the Mean Squared Error then optimize the thresholds.</li>
</ol>
</div>
</div>
<div id="outline-container-org324445f" class="outline-2">
<h2 id="org324445f">Other Sources</h2>
<div class="outline-text-2" id="text-org324445f">
</div>
<div id="outline-container-orged729be" class="outline-3">
<h3 id="orged729be">Classification</h3>
<div class="outline-text-3" id="text-orged729be">
<ul class="org-ul">
<li><a href="http://queirozf.com/entries/evaluation-metrics-for-classification-quick-examples-references">Evaluation Metrics for Classification Problems</a></li>
<li><a href="https://www.garysieling.com/blog/sklearn-gini-vs-entropy-criteria">Descision Trees: <i>Gini</i> vs <i>Entropy</i></a></li>
<li><a href="http://www.navan.name/roc/">Understanding ROC Curves</a></li>
</ul>
</div>
</div>
<div id="outline-container-org91978e5" class="outline-3">
<h3 id="org91978e5">Ranking</h3>
<div class="outline-text-3" id="text-org91978e5">
<ul class="org-ul">
<li>
<a href="https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf">Learning to Rank Using Gradient Descent</a> - source of pairwise AUC optimization</li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf">From RankNet to LambdaRank</a></li>
<li>
<a href="https://sourceforge.net/p/lemur/wiki/RankLib/">RankLib (implementation of the two previous papers</a>)</li>
<li><a href="https://wellecks.wordpress.com/2015/01/15/learning-to-rank-overview/">Learning to Rank Overview</a></li>
</ul>
</div>
</div>
<div id="outline-container-org82e5d75" class="outline-3">
<h3 id="org82e5d75">Clustering</h3>
<div class="outline-text-3" id="text-org82e5d75">
<ul class="org-ul">
<li><a href="http://nlp.uned.es/docs/amigo2007a.pdf">Comparison of clustering metrics</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgce36bdf" class="outline-2">
<h2 id="orgce36bdf">Practice Quiz</h2>
<div class="outline-text-2" id="text-orgce36bdf">
<ol class="org-ol">
<li>What would be a logloss value for a binary classification task if we use a constant predictor \(f(x)=0.5\)? Round to two decimal places.</li>
</ol>
<p>
-0.69 (marked as wrong)
</p>

<ol class="org-ol">
<li>What is the best constant predictor for the Mean Absolute Error?
<ul class="org-ul">
<li>Target 50th percentile, Target median</li>
</ul>
</li>

<li>The best constant predictor for the Mean Squared Error is:

<ul class="org-ul">
<li>Target Mean, average of the target vector</li>
</ul>
</li>
<li>The best Constant prediction for the Area Under the Curve is:
<ul class="org-ul">
<li>Any constant will lead to the same AUC value (should also mark target median, target mean, 1, 0.5, Target Mean divided by target variance - since any constant will lead to the same value, they are all the same)</li>
</ul>
</li>
<li>Suppose the target metric is \(r^2\), what optimization loss should we use for our models?
<ul class="org-ul">
<li>RMSE, MSE</li>
</ul>
</li>
<li>Calculate the AUC for these predictions:</li>
</ol>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">target</th>
<th scope="col" class="org-right">prediction</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">0.39</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">0.52</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-right">0.91</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-right">0.85</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-right">0.49</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">0.02</td>
</tr>
<tr>
<td class="org-right">0</td>
<td class="org-right">0.44</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre><span></span># from pypi
from sklearn.metrics import roc_auc_score
y_true = [1,0,1,1,1,0,0]
y_score = [0.39,0.52,0.91,0.85,0.49,0.02,0.44]
print(roc_auc_score(y_true, y_score))
</pre></div>

<pre class="example">
0.75

</pre>
</div>
</div>
<div id="outline-container-org8885982" class="outline-2">
<h2 id="org8885982">Quiz</h2>
<div class="outline-text-2" id="text-org8885982">
</div>
<div id="outline-container-org24e1008" class="outline-3">
<h3 id="org24e1008">One</h3>
<div class="outline-text-3" id="text-org24e1008">
<p>
Suppose we solve a binary classification task and our solution is scored with Log Loss. What predictions are preferable if all the true target values are 0?
</p>

<ul class="org-ul">
<li class="off">
<code>[ ]</code> (0.4, 0.5, 0.5, 0.6) - marked wrong</li>
<li class="on">
<code>[X]</code> (0.5, 0.5, 0.5, 0.5)</li>
<li class="off">
<code>[ ]</code> (0, 0, 0, 1)</li>
</ul>
<div class="highlight"><pre><span></span>import numpy
one = numpy.array([0.4, 0.5, 0.5, 0.6])
two = numpy.array([0.5, 0.5, 0.5, 0.5])
three = numpy.array([0, 0, 0, 1])

for guess in (one, two, three):
    print(sum(-numpy.log(1 - guess))/len(guess))
</pre></div>

<pre class="example">
0.7033526791900091
0.6931471805599453
inf
/home/hades/.virtualenvs/machine-learning-studies/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log
  import sys

</pre>
</div>
</div>

<div id="outline-container-org7f5bef6" class="outline-3">
<h3 id="org7f5bef6">Two</h3>
<div class="outline-text-3" id="text-org7f5bef6">
<p>
Suppose we solve a regression task and we optimize MSE. If we manage to lower MSE loss on either the training set or the test set, how would this affect the Pearson Correlation coefficient between the target vector and the predictions on the same set.
</p>

<p>
The correlation will also be lowered.
The correlation will not change.
</p>
<ul class="org-ul">
<li class="off">
<code>[ ]</code> The correlation will become larger. - marked wrong</li>
<li class="on">
<code>[X]</code> Any behavior is possible.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb4de534" class="outline-3">
<h3 id="orgb4de534">Three</h3>
<div class="outline-text-3" id="text-orgb4de534">
<p>
What would be a best constant prediction for a multi-class classification with four classes? The solution is scored with multi-class Log Loss. The number of objects in each class in the training set is 18, 3, 15, 24.
</p>

<ul class="org-ul">
<li>Guess one: 0,1,2,3</li>
</ul>
<div class="highlight"><pre><span></span>counts = numpy.array([18, 3, 15, 24])
print(counts/counts.sum())
</pre></div>

<pre class="example">
[0.3  0.05 0.25 0.4 ]

</pre>
</div>
</div>

<div id="outline-container-orged3cab1" class="outline-3">
<h3 id="orged3cab1">Four</h3>
<div class="outline-text-3" id="text-orged3cab1">
<p>
What is the best constant predictor for the r-squared metric?
</p>
<ul class="org-ul">
<li>one minus the target mean, target mean (0 points)</li>
<li>0.5 (0 points)</li>
<li>Target Mean (same as the MSE)</li>
</ul>
</div>
</div>
<div id="outline-container-org3852398" class="outline-3">
<h3 id="org3852398">Five</h3>
<div class="outline-text-3" id="text-org3852398">
<p>
Select the Correct statements
</p>
<ul class="org-ul">
<li class="on">
<code>[X]</code> Optimization loss can be the same as the target metric</li>
<li class="on">
<code>[X]</code> Optimization loss can be different from the target metric</li>
<li class="off">
<code>[ ]</code> Optimization loss is always different from the target metric</li>
<li class="off">
<code>[ ]</code> Optimization loss is always the same as the target metric</li>
</ul>
</div>
</div>

<div id="outline-container-orgfea6e6f" class="outline-3">
<h3 id="orgfea6e6f">Six</h3>
<div class="outline-text-3" id="text-orgfea6e6f">
<p>
Suppose the target metric is <b>M1</b> and the optimization loss is <b>M2</b>. We train a model and monitor its quality on a holdout set using the metrics <b>M1</b> and <b>M2</b>.
</p>

<p>
Select the correct statement:
</p>

<ul class="org-ul">
<li class="off">
<code>[ ]</code> If the best <b>M1</b> score is attained at iteration <i>N</i>, then the best <b>M2</b> score is always attained after the n-th iteration.</li>
<li class="off">
<code>[ ]</code> If the best <b>M1</b> score is attained at iteration <i>N</i>, then the best <b>M2</b> score is always attained before the n-th iteration.</li>
<li class="off">
<code>[ ]</code> If the best <b>M1</b> score is attained at iteration <i>N</i>, then the best <b>M2</b> score is always attained at the n-th iteration.</li>
<li class="on">
<code>[X]</code> There is no definite relation between the best iterations for the <b>M1</b> score and the <b>M2</b> score.</li>
</ul>
</div>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/optimizing-metrics/" class="u-url">Optimizing Metrics</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/optimizing-metrics/" rel="bookmark"><time class="published dt-published" datetime="2018-09-22T16:26:49-07:00" title="2018-09-22 16:26">2018-09-22 16:26</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/optimizing-metrics/#orge68c5a4">Mean Squared Error</a></li>
<li><a href="posts/optimizing-metrics/#org6ac307e">Mean Absolute Error</a></li>
<li><a href="posts/optimizing-metrics/#org47aa5a2">Mean Squared Probability Error and Mean Absolute Probability Error</a></li>
</ul>
</div>
</div>
<div id="outline-container-orge68c5a4" class="outline-2">
<h2 id="orge68c5a4">Mean Squared Error</h2>
<div class="outline-text-2" id="text-orge68c5a4">
<p>
This works, just use it as the optimization metric.
Sometimes this will be called <i>L2</i> loss.
</p>
</div>
</div>
<div id="outline-container-org6ac307e" class="outline-2">
<h2 id="org6ac307e">Mean Absolute Error</h2>
<div class="outline-text-2" id="text-org6ac307e">
<p>
Once again, this works so just use it.
Sometimes this will be called <i>L1</i> loss - it isn't as widely implemented.
</p>
</div>
</div>
<div id="outline-container-org47aa5a2" class="outline-2">
<h2 id="org47aa5a2">Mean Squared Probability Error and Mean Absolute Probability Error</h2>
<div class="outline-text-2" id="text-org47aa5a2">
<p>
Some libraries will let you use them as `sample_weights`
Some libraries (like sklearn) will require you to re-sample the data <code>df.sample(weights=sample_weights)</code>
Once you re-sample the data you can use any model that optimizes MSE or MAE
</p>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/general-approaches-to-metrics-optimization/" class="u-url">General Approaches to Metrics Optimization</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/general-approaches-to-metrics-optimization/" rel="bookmark"><time class="published dt-published" datetime="2018-09-22T16:04:35-07:00" title="2018-09-22 16:04">2018-09-22 16:04</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="outline-container-orgb3d5141" class="outline-2">
<h2 id="orgb3d5141">What do we mean by <i>loss</i> and <i>metric</i>?</h2>
<div class="outline-text-2" id="text-orgb3d5141">
<ul class="org-ul">
<li>the <code>metric</code> is what we <i>want</i> to optimize - but we sometimes don't really know how to optimize this, this is just how we evaluate the model in the end</li>
<li>
<code>loss</code> is what the model actually optimizes</li>
</ul>
</div>
</div>
<div id="outline-container-org3cbfad2" class="outline-2">
<h2 id="org3cbfad2">How do you optimize the target metric?</h2>
<div class="outline-text-2" id="text-org3cbfad2">
<ul class="org-ul">
<li>In some cases you can just use them (e.g. <i>MSE</i>, <i>logloss</i>)</li>
<li>In some cases you need to do a preprocessing training step with another metric
(e.g. <i>MSPE</i>, <i>MAPE</i>, <i>RMSLE</i>)</li>
<li>In osme cases you need to train on a different metric and then use post-processing during the prediction step</li>
</ul>
</div>
</div>
<div id="outline-container-org9202920" class="outline-2">
<h2 id="org9202920">Early Stopping</h2>
<div class="outline-text-2" id="text-org9202920">
<p>
To work around these problems, use two metrics <i>m1</i> and <i>m2</i> and optimize on metric <i>m1</i> while monitoring <i>m2</i>, then stop when <i>m2</i> is optimal.
</p>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/classification-metrics/" class="u-url">Classification Metrics</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/classification-metrics/" rel="bookmark"><time class="published dt-published" datetime="2018-09-22T15:35:29-07:00" title="2018-09-22 15:35">2018-09-22 15:35</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/classification-metrics/#orge7d1869">Accuracy</a></li>
<li><a href="posts/classification-metrics/#orgd89e10e">Logarithmic Loss</a></li>
<li><a href="posts/classification-metrics/#org2facf85">Area Under the ROC Curve (AUC)</a></li>
<li><a href="posts/classification-metrics/#orgbb68eb5">Quadratic Weighted Kappa (Cohen's Kappa)</a></li>
</ul>
</div>
</div>
<div id="outline-container-orge7d1869" class="outline-2">
<h2 id="orge7d1869">Accuracy</h2>
<div class="outline-text-2" id="text-orge7d1869">
<p>
This metric measures how frequently our model is correct.
</p>

<p>
\[
Accuracy = \frac{1}{N} \sum_{i=1}^N \left[\hat{y}_i = y_i \right]
\]
</p>

<p>
If you were to make a model that just predicted a constant value, the best value would be the most common one. This points out the fact that a severely imbalanced data set can have a model with high accuracy that isn't actually a particularly good one (it just predicts the most frequent classification all the time).
</p>
</div>
</div>
<div id="outline-container-orgd89e10e" class="outline-2">
<h2 id="orgd89e10e">Logarithmic Loss</h2>
<div class="outline-text-2" id="text-orgd89e10e">
</div>
<div id="outline-container-orgf72ee7b" class="outline-3">
<h3 id="orgf72ee7b">Binary Version</h3>
<div class="outline-text-3" id="text-orgf72ee7b">
<p>
\[
LogLoss = -\frac{1}{N} \sum_{i=1}^N y_i \log (\hat{y}_i) + (1 - y_i) \log (1 - \hat{y}_i)
\]
</p>
</div>
</div>
<div id="outline-container-orga7bced8" class="outline-3">
<h3 id="orga7bced8">Multiclass Version</h3>
<div class="outline-text-3" id="text-orga7bced8">
<p>
\[
LogLoss = -\frac{1}{N} \sum_{i=1}^N \sum_{i=1}^L y_{il} \log (\hat{y}_{il})
\]
</p>

<p>
Where <i>L</i> is the number of classes.
</p>

<p>
When compared to accuracy, accuracy is linear over the amount of error, while logarithmic loss grows exponentially the more error there is, so it more severely penalizes your model the more wrong it is.
</p>

<p>
If you wanted to make a constant prediction, the best constant is to set the constant(s) to the frequencies for each class.
</p>
</div>
</div>
</div>
<div id="outline-container-org2facf85" class="outline-2">
<h2 id="org2facf85">Area Under the ROC Curve (AUC)</h2>
<div class="outline-text-2" id="text-org2facf85">
<ul class="org-ul">
<li>only for binary classification</li>
<li>depends only on the ordering of the predictions, not the absolute values</li>
<li>can be thought of as the area under the curve or the ordering of pairs</li>
<li>The baseline score is 0.5</li>
</ul>
</div>
</div>
<div id="outline-container-orgbb68eb5" class="outline-2">
<h2 id="orgbb68eb5">Quadratic Weighted Kappa (Cohen's Kappa)</h2>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/metrics-optimization-2/" class="u-url">Metrics Optimization 2</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/metrics-optimization-2/" rel="bookmark"><time class="published dt-published" datetime="2018-09-19T08:04:33-07:00" title="2018-09-19 08:04">2018-09-19 08:04</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="outline-container-org19e5026" class="outline-2">
<h2 id="org19e5026">(R)MSPE, MAPE, and (R)MSLE</h2>
<div class="outline-text-2" id="text-org19e5026">
</div>
<div id="outline-container-org1cf2c17" class="outline-3">
<h3 id="org1cf2c17">An Off-By-One Example</h3>
<div class="outline-text-3" id="text-org1cf2c17">
<p>
Suppose we are predicting sales for two shops and the two shops have different sales volumes but our predictions for both cases are off by one. In this case our Mean-Squared-Error (MSE) might be the same, but they have a different significance.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-right">
<col class="org-right">
<col class="org-left">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-right">Shop</th>
<th scope="col" class="org-right">Actual</th>
<th scope="col" class="org-left">Predicted</th>
<th scope="col" class="org-right">MSE</th>
</tr></thead>
<tbody>
<tr>
<td class="org-right">1</td>
<td class="org-right">9</td>
<td class="org-left">10</td>
<td class="org-right">1</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-right">999</td>
<td class="org-left">1,000</td>
<td class="org-right">1</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="outline-container-orgc785c87" class="outline-2">
<h2 id="orgc785c87">Root Mean Squared Percentage Error and Mean Absolute Percentage Error</h2>
<div class="outline-text-2" id="text-orgc785c87">
<p>
The MSE and Mean-Absolute-Error (MAE) are absolute errors which don't take into account how significant the error is. There are two relative errors,  Mean-Squared-Percentage-Error (MSPE) and Mean-Absolute-Percentage-Error (MAPE) that divide each error term by the actual value to give you a realive error instead of an absolute error.
</p>

<p>
\[
MSPE = \frac{1}{N} \sum_{i=1}^n \left( \frac{y_i - \hat{y}}{y_i}\right)^2
\]
</p>

<p>
\[
MAPE = \frac{1}{N} \sum_{i=1}^n \left| \frac{y_i - \hat{y}}{y_i}\right|
\]
</p>

<p>
The MAPE will be inversely proportional to its target and the MSPE will be inversely proportional to the square of the target.
</p>
</div>

<div id="outline-container-orgdaad713" class="outline-3">
<h3 id="orgdaad713">Optimal Constant Predictions</h3>
<div class="outline-text-3" id="text-orgdaad713">
<p>
The best constant prediction you can make when using the Mean Squared Error is to predict the mean of the target values. The best prediction you can make for the MSPE is to take a weighted mean of the target values. The best constant prediction you can make for the Mean Absolute Percentage Error is the weighted median.
</p>
</div>
</div>
</div>

<div id="outline-container-org35ea739" class="outline-2">
<h2 id="org35ea739">Root Mean Squared Logarithmic Error (MSLE)</h2>
<div class="outline-text-2" id="text-org35ea739">
<p>
\[
MSLE = \sqrt{\frac{1}{N}\sum_{i=1}^N (\log (y_i + 1) - \log(\hat{y}_i + 1))^2}\\
= \sqrt{MSE(\log(y_i + 1), \log(\hat{y}_i + 1))}
\]
</p>

<p>
You add a 1 to each term to prevent you from trying to take the <i>log</i> of 0, which is undefined. The RMSLE is biased toward predictions that are higher than the actual values rather than lower.
</p>

<p>
These are the best constant predictions you can make for the competition data set.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-right">
</colgroup>
<thead><tr>
<th scope="col" class="org-left">Metric</th>
<th scope="col" class="org-right">Constant</th>
</tr></thead>
<tbody>
<tr>
<td class="org-left">MSE</td>
<td class="org-right">11</td>
</tr>
<tr>
<td class="org-left">RMSLE</td>
<td class="org-right">9.9</td>
</tr>
<tr>
<td class="org-left">MAE</td>
<td class="org-right">8</td>
</tr>
<tr>
<td class="org-left">MSPE</td>
<td class="org-right">6.6</td>
</tr>
<tr>
<td class="org-left">MAPE</td>
<td class="org-right">6</td>
</tr>
</tbody>
</table>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/metrics/" class="u-url">Metrics</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Cloistered Monkey
            </span></p>
            <p class="dateline"><a href="posts/metrics/" rel="bookmark"><time class="published dt-published" datetime="2018-09-17T21:49:35-07:00" title="2018-09-17 21:49">2018-09-17 21:49</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="posts/metrics/#orga4dac78">About Metrics</a></li>
<li><a href="posts/metrics/#org1c58ab3">The Most Common Metrics</a></li>
</ul>
</div>
</div>

<div id="outline-container-orga4dac78" class="outline-2">
<h2 id="orga4dac78">About Metrics</h2>
<div class="outline-text-2" id="text-orga4dac78">
</div>
<div id="outline-container-org3f23f45" class="outline-3">
<h3 id="org3f23f45">What are metrics?</h3>
<div class="outline-text-3" id="text-org3f23f45">
<p>
Metrics are numeric values that you are trying to optimize - they are how your model is graded.
</p>
</div>
</div>
<div id="outline-container-orge0acf78" class="outline-3">
<h3 id="orge0acf78">Why are there so many metrics?</h3>
<div class="outline-text-3" id="text-orge0acf78">
<p>
Each metric can tell you something different, so what metric you need depends on the problem you are trying to solve. For competitions, it is sometimes possible to do metrics probing just like you can sometimes do leaderboard probing to find peculiarities created by the chosen metric.
</p>
</div>
</div>
</div>
<div id="outline-container-org1c58ab3" class="outline-2">
<h2 id="org1c58ab3">The Most Common Metrics</h2>
<div class="outline-text-2" id="text-org1c58ab3">
</div>
<div id="outline-container-orgd104bd3" class="outline-3">
<h3 id="orgd104bd3">Regression</h3>
<div class="outline-text-3" id="text-orgd104bd3">
</div>
<div id="outline-container-orgdb9a946" class="outline-4">
<h4 id="orgdb9a946">Mean Squared Error</h4>
<div class="outline-text-4" id="text-orgdb9a946">
<p>
This is the average of the square of the errors.
\[
MSE = \frac{1}{N}
\]
</p>

<p>
The target mean value is the best constant prediction.
</p>
</div>
</div>
<div id="outline-container-org5248025" class="outline-4">
<h4 id="org5248025">Root Mean Squared Error</h4>
<div class="outline-text-4" id="text-org5248025">
<p>
This is the square root of the mean squared error.
</p>
<ul class="org-ul">
<li>minimizing the RMSE is also minimizes the MSE</li>
<li>RMSE is more intuitive</li>
<li>They can differ when used by gradient-based models</li>
</ul>
</div>
</div>
<div id="outline-container-orgf96fba4" class="outline-4">
<h4 id="orgf96fba4">R-squared</h4>
<div class="outline-text-4" id="text-orgf96fba4">
<ul class="org-ul">
<li>Optimizing r-squared is equivalent to optimizing MSE</li>
</ul>
</div>
</div>
<div id="outline-container-orge8653a1" class="outline-4">
<h4 id="orge8653a1">Mean Absolute Error</h4>
<div class="outline-text-4" id="text-orge8653a1">
<p>
This is more common when you are explaining it to a non-statistician. It is also more robust. Mathematically, it isn't something that you can calculate the derivate for.
</p>

<p>
The target median is the best constant prediction.
</p>
</div>
</div>
<div id="outline-container-org6b02d49" class="outline-4">
<h4 id="org6b02d49">MAE vs MSE</h4>
<div class="outline-text-4" id="text-org6b02d49">
<ul class="org-ul">
<li>Outliers: use MAE</li>
<li>Unexpected Values that we should still care about (not true outliers (mistakes), just rare): use MSE</li>
</ul>
</div>
</div>
</div>
</div>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="next">
                <a href="index-3.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2018         <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png"></a><br>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
